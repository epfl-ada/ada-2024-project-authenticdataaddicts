{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddaee4c",
   "metadata": {},
   "source": [
    "# CMU Movie data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8ac0f",
   "metadata": {},
   "source": [
    "The following code dowloads the datasets that were too heavy to be included, and places them directly in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "13d88e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load functions\n",
    "from src.utils.import_TMDb import import_TMDb\n",
    "from src.utils.get_IMDb_dataset import get_IMDb_dataset\n",
    "\n",
    "\n",
    "#Download TMDb Dataset\n",
    "import_TMDb()\n",
    "#Download IMDb Dataset\n",
    "get_IMDb_dataset(\"name.basics.tsv\")\n",
    "get_IMDb_dataset(\"title.ratings.tsv\")\n",
    "get_IMDb_dataset(\"title.principals.tsv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5340b",
   "metadata": {},
   "source": [
    "## Initial data inspection\n",
    "We will first try to provide a first generic inspection of the CMU movie dataset we decided to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b837b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from src.utils.data_utils import *\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f50aa3",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "The dataset is divided in 3 parts, the characters, the movies and the plots of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data, movie_data, plot_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd05ad",
   "metadata": {},
   "source": [
    "### Characters dataset\n",
    "Let's first have a look to the character dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b789d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {character_data.shape[0]} characters with {character_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72305a3",
   "metadata": {},
   "source": [
    "We can note that the actor ethnicity need to be transformed to readable value (for now, it looks to be freebase id)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4b58d",
   "metadata": {},
   "source": [
    "Let's see if we have a lot of missing data. We will also check that we don't have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec456244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the characters dataset for each features:\")\n",
    "print(character_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec919b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {character_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471ea5a",
   "metadata": {},
   "source": [
    "We see that we miss a lot of character names/ids, actor heights, ethnicity and age at release."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4be89",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "Let's now have a look at the movies dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af339272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {movie_data.shape[0]} movies with {movie_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcaf5d",
   "metadata": {},
   "source": [
    "We can note that the languages, countries and genres need to be preprocessed (for now dictionnary with id->readablename)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a5ea",
   "metadata": {},
   "source": [
    "Let's now see if we have a lot of missing data. We will also verify that we don't have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82985100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the movies dataset for each features:\")\n",
    "print(movie_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465283a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {movie_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71496d7e",
   "metadata": {},
   "source": [
    "Ouch! We only have box office revenue for 10% of our movies, that's not good news since it's a key feature in our research problematic, we will need to fix this. Apart from this, we can also note that we are missing 25% of the runtime information. We could try to improve this. This also applies to the movie release data. For the languages, countries and genres, we note that they are dictionaries meaning that we first need to preprocess them a bit (for example transforming them to a list) to then be able to see the percentage of missing data. We will do it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the readable values for 'languages', 'countries', and 'genres' columns. Also clean the language column.\n",
    "\n",
    "movie_data['languages'] = movie_data['languages'].apply(lambda x: extract_values(x, clean_func=clean_language))\n",
    "movie_data['countries'] = movie_data['countries'].apply(lambda x: extract_values(x)) \n",
    "movie_data['genres'] = movie_data['genres'].apply(lambda x: extract_values(x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f611732",
   "metadata": {},
   "source": [
    "We can now have a look to the missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of None (NaN) values for each column\n",
    "none_languages = movie_data['languages'].isna().mean()\n",
    "none_countries = movie_data['countries'].isna().mean()\n",
    "none_genres = movie_data['genres'].isna().mean()\n",
    "\n",
    "# Print the counts of None (NaN) values\n",
    "print(f\"Percentage of None values in 'languages': {none_languages:.2%}\")\n",
    "print(f\"Percentage of None values in 'countries': {none_countries:.2%}\")\n",
    "print(f\"Percentage of None values in 'genres': {none_genres:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6999f",
   "metadata": {},
   "source": [
    "This looks ok overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ee937",
   "metadata": {},
   "source": [
    "### Plot summary dataset\n",
    "Let's now have a look at the plot summaries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {plot_data.shape[0]} plot summaries with {plot_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f05e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec2b3e",
   "metadata": {},
   "source": [
    "Let's see if we have some rows that are invalid (no summary or wikipedia id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead77807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pourcentage of null rows in the plot summaries dataset:\")\n",
    "print(plot_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353cf7c",
   "metadata": {},
   "source": [
    "Good new, we have nothing missing here :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5a1f3",
   "metadata": {},
   "source": [
    "## Data completion + first preprocessing\n",
    "Before going deeper to the analysis, we want to already fix some problems we pointed out.\n",
    "\n",
    "Movies:\n",
    "- A lot of box office revenus missing\n",
    "\n",
    "Characters:\n",
    "- We first note that we need to preprocess the actor ethnicity that look to be a freebase id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db19e1f",
   "metadata": {},
   "source": [
    "### Movies problems\n",
    "\n",
    "Let's first to get more data on box office results to decrease the number of missing data we have for now. To do this, we will merge the current dataset with a dataset that contains information about 1,000,000 movies collected from The Movie Database (TMDb), including revenue and runtime (https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset (and rename some columns)\n",
    "movies_dataset = pd.read_csv('data/tmbd_movies.csv')\n",
    "movies_dataset['box_office_revenue'] = pd.to_numeric(movies_dataset['revenue'], errors='coerce') \n",
    "movies_dataset['release_date'] = pd.to_datetime(movies_dataset['release_date'], errors='coerce')\n",
    "\n",
    "# We remove the nan of movie release date since we merge on it\n",
    "movie_data['movie_release_date'] = pd.to_datetime(movie_data['movie_release_date'], errors='coerce')\n",
    "movie_data = movie_data.dropna(subset=['movie_release_date'])\n",
    "\n",
    "movies_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"box_office_revenue\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac46c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on title) with wikidata: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on title) with wikidata: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7011b5",
   "metadata": {},
   "source": [
    "Big improvement, that's good. Let's try to improve the runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f19049",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"runtime\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Runtime results missing percentage before merge (on title) with The Movies Dataset: {before_missing:.2%}\")\n",
    "print(f\"Runtime results missing percentage after merge (on title) with The Movies Dataset: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc622e09",
   "metadata": {},
   "source": [
    "That's pretty cool too, we also want to get the IMBD ID column because we need it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, _, _ = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"imdb_id\", merge_strategy='add_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d8803",
   "metadata": {},
   "source": [
    "### Characters problems\n",
    "\n",
    "TODO: Improve missing characters (maybe not needed, see the \"Do we have data on all lead actors\") -> I think it's not really needed because of the results we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfd011",
   "metadata": {},
   "source": [
    "## Getting the rating and lead actors of movies\n",
    "\n",
    "Now we want to merge with the IMDb datasets (https://developer.imdb.com/non-commercial-datasets/) in order to obtain ratings and lead actors. We consider an actor to be a lead actor if their ordering is 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb ratings and select relevant columns\n",
    "imdb_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "imdb_ratings = imdb_ratings.rename(columns={'tconst': 'imdb_id'})\n",
    "imdb_ratings = imdb_ratings[['imdb_id', 'averageRating', 'numVotes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb names data for actors\n",
    "imdb_names = pd.read_csv('data/name.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c549c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold chunks of filtered lead actors\n",
    "filtered_lead_actors = []\n",
    "\n",
    "# Process imdb_principals in chunks to reduce memory usage\n",
    "for chunk in pd.read_csv('data/title.principals.tsv', sep='\\t', chunksize=100000):\n",
    "    # Filter for lead actors (first and second-billed actor or actress)\n",
    "    chunk_lead_actors = chunk[\n",
    "        (chunk['category'].isin(['actor', 'actress'])) & \n",
    "        (chunk['ordering'].isin([1, 2]))\n",
    "    ][['tconst', 'nconst', 'ordering']]\n",
    "    \n",
    "    # Append the filtered chunk to the list\n",
    "    filtered_lead_actors.append(chunk_lead_actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all filtered chunks into a single DataFrame\n",
    "lead_actors = pd.concat(filtered_lead_actors)\n",
    "\n",
    "# Rename columns and merge with imdb_names DataFrame to get actor names\n",
    "lead_actors = lead_actors.rename(columns={'tconst': 'imdb_id'})\n",
    "lead_actors = lead_actors.merge(imdb_names[['nconst', 'primaryName']], on='nconst', how='left')\n",
    "\n",
    "# Pivot to get separate columns for the first and second lead actors\n",
    "lead_actors = lead_actors.pivot(index='imdb_id', columns='ordering', values='primaryName').reset_index()\n",
    "lead_actors.columns = ['imdb_id', 'lead_actor_1', 'lead_actor_2']\n",
    "\n",
    "# Merge movies_wikidata_merged_imdbid with IMDb ratings\n",
    "imdb_merged_movie_data = pd.merge(movie_data_merged, imdb_ratings, on='imdb_id', how='left')\n",
    "\n",
    "# Merge with lead actors data\n",
    "merged_movie_data = imdb_merged_movie_data.merge(lead_actors, on='imdb_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movie_data = merged_movie_data.drop_duplicates(subset=['imdb_id'])\n",
    "merged_movie_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d15017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {merged_movie_data.shape[0]} rows in our merged movies dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db28a2",
   "metadata": {},
   "source": [
    "## Cleaning and removing outliers\n",
    "\n",
    "Before analyzing the data any further, let's remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9903b82",
   "metadata": {},
   "source": [
    "### Character dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facc89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dob to date\n",
    "character_data.loc[:, \"actor_dob\"] = pd.to_datetime(character_data[\"actor_dob\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only non-NaN values for all columns\n",
    "not_na_height = character_data[\"actor_height\"].notna()\n",
    "not_na_age_at_release = character_data[\"actor_age_at_release\"].notna()\n",
    "not_na_gender = character_data[\"actor_gender\"].notna()\n",
    "not_na_ethnicity = character_data[\"actor_ethnicity\"].notna()\n",
    "not_na_name_char = character_data[\"character_name\"].notna()\n",
    "not_na_dob = character_data[\"actor_dob\"].notna()\n",
    "\n",
    "# Combine all conditions into one mask\n",
    "not_na_mask = not_na_height & not_na_age_at_release & not_na_gender & not_na_ethnicity & not_na_name_char & not_na_dob\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "character_data_cleaned = character_data.copy()[not_na_mask]\n",
    "\n",
    "# Calculate reduction in size\n",
    "reduction = 1 - character_data_cleaned.shape[0] / character_data.shape[0]\n",
    "print(f\"Removing NaN reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fceddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid heights (between 1.5 and 2.8 meters)\n",
    "character_data_valid_heights = character_data_cleaned.query(\"actor_height > 1.5 and actor_height < 2.8\")\n",
    "reduction = (len(character_data_cleaned) - len(character_data_valid_heights)) / len(character_data_cleaned)\n",
    "\n",
    "print(f\"Removing invalid actor heights reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2568b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid ages (between 0 and 100 years)\n",
    "character_data_valid_ages = character_data_valid_heights.query(\"actor_age_at_release > 0 and actor_age_at_release < 100\")\n",
    "reduction = (len(character_data_valid_heights) - len(character_data_valid_ages)) / len(character_data_valid_heights)\n",
    "\n",
    "print(f\"Removing invalid actor ages reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only ethnicity labels that are common\n",
    "min_occurrence = 10\n",
    "ethnicity_label_counts = character_data_valid_ages['actor_ethnicity_label'].value_counts()\n",
    "ethnicity_labels = ethnicity_label_counts[ethnicity_label_counts > min_occurrence]\n",
    "\n",
    "mask = character_data_valid_ages['actor_ethnicity_label'].isin(ethnicity_labels.index)\n",
    "character_data_valid = character_data_valid_ages[mask]\n",
    "\n",
    "reduction = 1 - len(character_data_valid) / len(character_data_valid_ages)\n",
    "\n",
    "print(f\"Removing ethnicity labels which are uncommon reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final dataset size\n",
    "print(f\"Number of characters after preprocessing: {character_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "character_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e02989",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "\n",
    "We will also remove the outliers and preprocess the movie dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e727d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated columns\n",
    "movie_data_extracted = merged_movie_data.drop(columns=['title', 'release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lead_actor_2 to NaN where it is the same as lead_actor_1\n",
    "movie_data_extracted.loc[movie_data_extracted['lead_actor_1'] == movie_data_extracted['lead_actor_2'], 'lead_actor_2'] = pd.NA\n",
    "\n",
    "# Remove movies where we don't have lead actor\n",
    "movie_data_extracted = movie_data_extracted.dropna(subset=['lead_actor_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6268dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only non-NaN values for all columns (the other columns have no missing values)\n",
    "not_na_release_date = movie_data_extracted[\"movie_release_date\"].notna()\n",
    "not_na_runtime = movie_data_extracted[\"runtime\"].notna()\n",
    "not_na_languages = movie_data_extracted[\"languages\"].notna()\n",
    "not_na_countries = movie_data_extracted[\"countries\"].notna()\n",
    "not_na_genres = movie_data_extracted[\"genres\"].notna()\n",
    "not_na_lead_actor_1 = movie_data_extracted[\"lead_actor_1\"].notna()\n",
    "not_na_box_office = movie_data_extracted[\"box_office_revenue\"].notna()\n",
    "not_na_average_rating = movie_data_extracted[\"averageRating\"].notna()\n",
    "\n",
    "# Combine all conditions into one mask\n",
    "not_na_mask = not_na_release_date & not_na_runtime & not_na_languages & not_na_countries & not_na_genres & not_na_lead_actor_1 & not_na_box_office & not_na_average_rating\n",
    "\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "movie_data_cleaned = movie_data_extracted[not_na_mask]\n",
    "\n",
    "# Calculate reduction in size\n",
    "reduction = 1 - movie_data_cleaned.shape[0] / movie_data_extracted.shape[0]\n",
    "print(f\"Removing NaN reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a768ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only movies released between 1940 and 2012\n",
    "movie_data_valid_release_dates = movie_data_cleaned[movie_data_cleaned[\"movie_release_date\"]>'1-1-1940']\n",
    "\n",
    "reduction = 1 - movie_data_valid_release_dates.shape[0]/ movie_data_cleaned.shape[0]\n",
    "print(f\"Removing movies released before 1940 reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e34c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only movies that last under 200 min\n",
    "movie_data_valid_runtime = movie_data_valid_release_dates[movie_data_valid_release_dates[\"runtime\"]<200]\n",
    "\n",
    "reduction = 1 - movie_data_valid_runtime.shape[0]/ movie_data_valid_release_dates.shape[0]\n",
    "print(f\"Removing movies lasting more than 3 hours 20mins reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b59a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only movies that last at least 1h\n",
    "movie_data_valid_runtime = movie_data_valid_runtime[movie_data_valid_runtime[\"runtime\"]>60]\n",
    "\n",
    "reduction = 1 - movie_data_valid_runtime.shape[0]/ movie_data_valid_release_dates.shape[0]\n",
    "print(f\"Removing movies less than 1h: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e3e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only movies that have at least 500 votes\n",
    "movie_data_valid_votes = movie_data_valid_runtime[movie_data_valid_runtime[\"numVotes\"]>500]\n",
    "\n",
    "reduction = 1 - movie_data_valid_votes.shape[0]/ movie_data_valid_runtime.shape[0]\n",
    "print(f\"Removing movies that have less than 500 votes: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_valid = movie_data_valid_votes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0252f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of movies after preprocessing: {movie_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "movie_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893cdd2",
   "metadata": {},
   "source": [
    "## Do we have data for the lead actors\n",
    "\n",
    "Now that we have the two main actors of each movie, let's see if we have their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique pairs of (freebase_movie_id, lead_actor) from the movie dataset\n",
    "lead_actor_pairs = pd.concat([\n",
    "    movie_data_valid[['freebase_movie_id', 'lead_actor_1']].rename(columns={'lead_actor_1': 'actor_name'}),\n",
    "    movie_data_valid[['freebase_movie_id', 'lead_actor_2']].rename(columns={'lead_actor_2': 'actor_name'})\n",
    "])\n",
    "\n",
    "# Convert the DataFrame of pairs to a list of tuples for filtering\n",
    "lead_actor_pairs = list(lead_actor_pairs.itertuples(index=False, name=None))\n",
    "\n",
    "# Filter character_data to keep only rows where (freebase_movie_id, actor_name) matches the pairs in lead_actor_pairs\n",
    "lead_actor_data = character_data_valid[\n",
    "    character_data_valid[['freebase_movie_id', 'actor_name']].apply(tuple, axis=1).isin(lead_actor_pairs)\n",
    "]\n",
    "\n",
    "# Check for missing values in key columns\n",
    "print(\"Missing values in lead actor data:\")\n",
    "print(lead_actor_data[['actor_name', 'actor_dob', 'actor_gender', 'actor_ethnicity', 'actor_height', 'actor_age_at_release']].isna().mean()*100)\n",
    "\n",
    "# Display the first few rows of the filtered data\n",
    "lead_actor_data.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653bfc3",
   "metadata": {},
   "source": [
    "This make sense since we preprocessed our character data, let's now see if we have data for all of our actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have data for {lead_actor_data.shape[0]/(movie_data_valid[\"lead_actor_1\"].notna().sum() + movie_data_valid[\"lead_actor_2\"].notna().sum())*100}% ({lead_actor_data.shape[0]} actors) of our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be30b0",
   "metadata": {},
   "source": [
    "Ok good, let's now create a subset dataframe that will contains only the movies for which we have data on the lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd31290",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_movies_with_lead_actors_data = movie_data_valid[movie_data_valid['freebase_movie_id'].isin(lead_actor_data['freebase_movie_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_movies_with_lead_actors_data.shape[0]} movies for which we have full data on our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34957642",
   "metadata": {},
   "source": [
    "We can also extract the characters that are part of this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the character_data_valid dataset to keep only rows with freebase_movie_id present in movie_data_extracted\n",
    "subset_characters_with_lead_actor_data = character_data_valid[character_data_valid['freebase_movie_id'].isin(subset_movies_with_lead_actors_data['freebase_movie_id'])]\n",
    "\n",
    "# Extract the relevant columns for characters and associated movies\n",
    "subset_characters_with_lead_actor_data = subset_characters_with_lead_actor_data[['actor_name', 'actor_dob', 'actor_gender', 'actor_ethnicity', 'actor_height', 'actor_age_at_release', 'freebase_movie_id', 'character_name']]\n",
    "\n",
    "# Display the first few rows of the filtered and extracted data\n",
    "subset_characters_with_lead_actor_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_characters_with_lead_actor_data.shape[0]} characters for the subset movies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56351b7",
   "metadata": {},
   "source": [
    "## Saving our newly created dataframes\n",
    "\n",
    "We will save our five dataframes:\n",
    "\n",
    "- full_movie_data_preprocessed that contains all the movies preprocessed \n",
    "- full_characters_data_preprocessed that contains all the characters preprocessed\n",
    "- subset_movies_with_lead_actors_data that contains movies where we have data on all the lead actors\n",
    "- lead_actors_data_on_subset_movie that contains information on the lead actors of the previous subset\n",
    "- character_data_valid_filtered that contains information on all the characters of the previous subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Pickle\n",
    "movie_data_extracted.to_pickle('data/full_movie_data_preprocessed.pkl')\n",
    "character_data_valid.to_pickle('data/full_characters_data_preprocessed.pkl')\n",
    "subset_movies_with_lead_actors_data.to_pickle('data/subset_movie_with_full_data_on_lead_actors.pkl')\n",
    "lead_actor_data.to_pickle('data/lead_actors_data_on_subset_movie.pkl')\n",
    "subset_characters_with_lead_actor_data.to_pickle('data/characters_data_on_subset_movie.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356afe5",
   "metadata": {},
   "source": [
    "## Loading our dataframes\n",
    "\n",
    "We can skip all the preprocessing process and load our dataframes directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets from pickle files\n",
    "full_movie_data_preprocessed = pd.read_pickle('data/full_movie_data_preprocessed.pkl')\n",
    "full_characters_data_preprocessed = pd.read_pickle('data/full_characters_data_preprocessed.pkl')\n",
    "subset_movie_with_full_data_on_lead_actors = pd.read_pickle('data/subset_movie_with_full_data_on_lead_actors.pkl')\n",
    "lead_actors_data_on_subset_movie = pd.read_pickle('data/lead_actors_data_on_subset_movie.pkl')\n",
    "characters_data_on_subset_movie = pd.read_pickle('data/characters_data_on_subset_movie.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab0a23",
   "metadata": {},
   "source": [
    "## Deeper analysis\n",
    "Now that our data is more complete, we can do a more in deep analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951bc2b",
   "metadata": {},
   "source": [
    "### Lead actors dataset \n",
    "\n",
    "Let's first analyze our dataframe with the lead actors just created. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_actors_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74caf699",
   "metadata": {},
   "source": [
    "Let's print their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the height of actors\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_height\", bins=25, ax=axes[0], kde=False)\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "\n",
    "# Histogram for the actors' age at release\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], kde=True)\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2], kde=True)\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5558c",
   "metadata": {},
   "source": [
    "Let's now lets explore the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Countplot for the gender distribution\n",
    "sns.countplot(data=lead_actors_data_on_subset_movie, x=\"actor_gender\", ax=axes[0], stat='proportion')\n",
    "axes[0].set_title(\"Actor gender distribution\")\n",
    "axes[0].set_xlabel(\"Gender\")\n",
    "axes[0].set_ylabel(\"Proportion\")\n",
    "\n",
    "ethnicity_cutoff = 30\n",
    "values = lead_actors_data_on_subset_movie[\"actor_ethnicity_label\"].value_counts()\n",
    "values = values[:ethnicity_cutoff]\n",
    "sns.barplot(x=values, y=values.index, ax=axes[1])\n",
    "axes[1].set_title(f\"{ethnicity_cutoff} most common ethnicity label\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Ethnicity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7792b",
   "metadata": {},
   "source": [
    "### Movies dataset \n",
    "\n",
    "Let's now analyse our movies dataset. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_completed = full_movie_data_preprocessed.copy()\n",
    "movie_data_completed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9a852",
   "metadata": {},
   "source": [
    "Let's print their distributions (except for the wikipedia id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "movie_data_completed[\"runtime\"].hist(bins=100, ax=axes[0])\n",
    "axes[0].set_title(\"Histogram for runtime\")\n",
    "axes[0].set_xlabel(\"Runtime (min)\")\n",
    "\n",
    "# Histogram for the box office results\n",
    "movie_data_completed[\"box_office_revenue\"].hist(bins=100, ax=axes[1])\n",
    "axes[1].set_title(\"Histogram for box_office_revenue\")\n",
    "axes[1].set_xlabel(\"Box office revenue (dollars)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2f59c",
   "metadata": {},
   "source": [
    "Let's now print some box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Boxplot for the raw box_office_revenue\n",
    "sns.boxplot(data=movie_data_completed[\"box_office_revenue\"], ax=axes[0])\n",
    "axes[0].set_title(\"Boxplot for box_office_revenue\")\n",
    "\n",
    "# Boxplot for the raw runtime\n",
    "sns.boxplot(data=movie_data_completed[\"runtime\"], ax=axes[1])\n",
    "axes[1].set_title(\"Boxplot for runtime\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999cca21",
   "metadata": {},
   "source": [
    "TODO : remove if needed\n",
    "\n",
    "It seems a lot of movies have a box office of 0 dollar, let's investigate this a little further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d20cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_0_box_office = len(movie_data_completed[movie_data_completed['box_office_revenue']==0])\n",
    "print(f'There are {nb_0_box_office} movies that generate 0 revenue, over {movie_data_completed.shape[0]} in total.')\n",
    "print(f'This represents {nb_0_box_office/movie_data_completed.shape[0]:.2%} of the movies.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409a43f",
   "metadata": {},
   "source": [
    "Let's look a little at the movies with a non-zero box office:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_non_zero_bo = movie_data_completed[movie_data_completed['box_office_revenue']>0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the revenue of non-zero box office movies\n",
    "sns.boxplot(data=movie_data_non_zero_bo[\"box_office_revenue\"], ax=axes[0])\n",
    "axes[0].set_title(\"Boxplot for non-zero box_office_revenue\")\n",
    "\n",
    "# Histogram for the non-zero box office results\n",
    "movie_data_non_zero_bo[\"box_office_revenue\"].hist(bins=100, ax=axes[1])\n",
    "axes[1].set_title(\"Histogram for non-zero box_office_revenue\")\n",
    "axes[1].set_xlabel(\"Box office revenue (dollars)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c2eb7",
   "metadata": {},
   "source": [
    "Let's now look at the ratings and number of votes per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the movie ratings\n",
    "rating_intervals = np.arange(0, 11, 1)\n",
    "movie_data_completed['averageRating'].hist(bins=rating_intervals, ax=axes[0], grid=False)\n",
    "\n",
    "axes[0].set_xlabel('Rating intervals')\n",
    "axes[0].set_xticks(rating_intervals)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Histogram for movie ratings')\n",
    "\n",
    "# Histogram for the number of votes\n",
    "numvotes_intervals = [0, 10, 100, 1e3, 1e4, 1e5, 1e6, movie_data_completed['numVotes'].max()]\n",
    "movie_data_completed['numVotes'].hist(bins=numvotes_intervals, ax=axes[1], grid=False)\n",
    "\n",
    "axes[1].set_xlabel('Number of votes')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Histogram for number of votes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfe28f",
   "metadata": {},
   "source": [
    "We can now have a look at the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "cutoff = 20 \n",
    "\n",
    "# Flatten the columns containing the lists of languages\n",
    "movie_languages_flat = movie_data_completed['languages'].explode()\n",
    "values = movie_languages_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "# Countplot for the languages distribution\n",
    "sns.barplot(x=values, y=values.index, ax=axes[0])\n",
    "axes[0].set_title(f\"{cutoff} most common languages\")\n",
    "axes[0].set_xlabel(\"Count\")\n",
    "axes[0].set_ylabel(\"Language\")\n",
    "\n",
    "# Flatten the columns containing the lists of countries\n",
    "movie_countries_flat = movie_data_completed['countries'].explode()\n",
    "values = movie_countries_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "# Countplot for the countries distribution\n",
    "sns.barplot(x=values, y=values.index, ax=axes[1])\n",
    "axes[1].set_title(f\"{cutoff} most common countries\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Country\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95a393",
   "metadata": {},
   "source": [
    "As we can expect, the English language and United States of America clearly dominate the movie industry.\n",
    "\n",
    "Let's now look at the most common genres that appear in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_cutoff = 30\n",
    "# Flatten the columns containing the lists of genres\n",
    "movie_genres_flat = movie_data_completed['genres'].explode()\n",
    "values = movie_genres_flat.value_counts()\n",
    "values = values[:genres_cutoff]\n",
    "# Countplot for the languages distribution\n",
    "ax = sns.barplot(x=values, y=values.index)\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Genres')\n",
    "ax.set_title(f'{genres_cutoff} most common genres');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: do we need more plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f48297",
   "metadata": {},
   "source": [
    "### Characters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceeae5f",
   "metadata": {},
   "source": [
    "We now analyze the dataframe with the characters (including non-lead actors). We again start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff57aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c2f07",
   "metadata": {},
   "source": [
    "Let's do some plots to visualize better. As it is very similar as the plots from the lead actors dataset, we will compare our plots with the ones from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ab151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label variables to ensure uniform legends in the plots\n",
    "label_all = \"All actors\"\n",
    "label_lead = \"Lead actors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the height of actors\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_height\", bins=25, ax=axes[0], \n",
    "             kde=False, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_height\", bins=25, \n",
    "             ax=axes[0], kde=False, stat='percent', label=label_lead)\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogram for the age of actors at release\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], \n",
    "             kde=True, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], \n",
    "             kde=True, stat='percent', label=label_lead)\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2], \n",
    "             kde=True, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2],\n",
    "             kde=True, stat='percent', label=label_lead)\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2ecd5",
   "metadata": {},
   "source": [
    "Finally we compare the gender distribution between all actors and only lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556887b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "width = 0.4\n",
    "\n",
    "gender_dist_all = characters_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "gender_dist_lead = lead_actors_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "labels = list(gender_dist_all.keys())\n",
    "\n",
    "bar_all = ax.bar(labels, gender_dist_all, -width, label=label_all, align='edge')\n",
    "bar_lead = ax.bar(labels, gender_dist_lead, width, label=label_lead, align='edge')\n",
    "\n",
    "ax.set_title(\"Comparison of actors' gender distribution between lead roles and all roles\")\n",
    "ax.set_xlabel(\"Gender\")\n",
    "ax.set_ylabel(\"Percent\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
