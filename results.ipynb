{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddaee4c",
   "metadata": {},
   "source": [
    "# CMU Movie data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8ac0f",
   "metadata": {},
   "source": [
    "## Downloading datasets\n",
    "The following code dowloads the datasets that were too heavy to be included, and places them directly in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d88e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load functions\n",
    "from src.utils.import_TMDb import import_TMDb\n",
    "from src.utils.get_IMDb_dataset import get_IMDb_dataset\n",
    "\n",
    "\n",
    "#Download TMDb Dataset\n",
    "import_TMDb()\n",
    "#Download IMDb Dataset\n",
    "get_IMDb_dataset(\"name.basics.tsv\")\n",
    "get_IMDb_dataset(\"title.ratings.tsv\")\n",
    "get_IMDb_dataset(\"title.principals.tsv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5340b",
   "metadata": {},
   "source": [
    "## Initial data inspection\n",
    "We will first try to provide a first generic inspection of the CMU movie dataset we decided to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b837b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from src.utils.data_utils import *\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f50aa3",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "The dataset is divided in 3 parts, the characters, the movies and the plots of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data, movie_data, plot_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd05ad",
   "metadata": {},
   "source": [
    "### Characters dataset\n",
    "Let's first have a look to the character dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b789d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {character_data.shape[0]} characters with {character_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72305a3",
   "metadata": {},
   "source": [
    "Note that we have mapped the ethnicity id to a real label (see freebase.py for details on how we got the map)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4b58d",
   "metadata": {},
   "source": [
    "Let's see if we have a lot of missing data. We will also check that we don't have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec456244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the characters dataset for each features:\")\n",
    "print(character_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec919b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {character_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471ea5a",
   "metadata": {},
   "source": [
    "We see that we miss a lot of character names/ids, actor heights, ethnicity and age at release."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4be89",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "Let's now have a look at the movies dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af339272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {movie_data.shape[0]} movies with {movie_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcaf5d",
   "metadata": {},
   "source": [
    "We can note that the languages, countries and genres need to be preprocessed (for now dictionnary with id->readablename)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a5ea",
   "metadata": {},
   "source": [
    "Let's now see if we have a lot of missing data. We will also verify that we don't have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82985100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the movies dataset for each features:\")\n",
    "print(movie_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465283a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {movie_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71496d7e",
   "metadata": {},
   "source": [
    "Ouch! We only have box office revenue for 10% of our movies, that's not good news since it's a key feature in our research problematic, we will need to fix this. Apart from this, we can also note that we are missing 25% of the runtime information. We could try to improve this. This also applies to the movie release data. For the languages, countries and genres, we note that they are dictionaries meaning that we first need to preprocess them a bit (for example transforming them to a list) to then be able to see the percentage of missing data. We will do it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the readable values for 'languages', 'countries', and 'genres' columns. Also clean the language column.\n",
    "\n",
    "movie_data['languages'] = movie_data['languages'].apply(lambda x: extract_values(x, clean_func=clean_language))\n",
    "movie_data['countries'] = movie_data['countries'].apply(lambda x: extract_values(x)) \n",
    "movie_data['genres'] = movie_data['genres'].apply(lambda x: extract_values(x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f611732",
   "metadata": {},
   "source": [
    "We can now have a look to the missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of None (NaN) values for each column\n",
    "none_languages = movie_data['languages'].isna().mean()\n",
    "none_countries = movie_data['countries'].isna().mean()\n",
    "none_genres = movie_data['genres'].isna().mean()\n",
    "\n",
    "# Print the counts of None (NaN) values\n",
    "print(f\"Percentage of None values in 'languages': {none_languages:.2%}\")\n",
    "print(f\"Percentage of None values in 'countries': {none_countries:.2%}\")\n",
    "print(f\"Percentage of None values in 'genres': {none_genres:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6999f",
   "metadata": {},
   "source": [
    "This looks ok overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ee937",
   "metadata": {},
   "source": [
    "### Plot summary dataset\n",
    "Let's now have a look at the plot summaries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {plot_data.shape[0]} plot summaries with {plot_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f05e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec2b3e",
   "metadata": {},
   "source": [
    "Let's see if we have some rows that are invalid (no summary or wikipedia id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead77807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pourcentage of null rows in the plot summaries dataset:\")\n",
    "print(plot_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353cf7c",
   "metadata": {},
   "source": [
    "Good new, we have nothing missing here :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5a1f3",
   "metadata": {},
   "source": [
    "## Data completion\n",
    "Before going deeper to the analysis, we want to already fix the fact that we are missing data for most of the box office results and some runtime values.\n",
    "\n",
    "Let's then first to get more data on box office results to decrease the number of missing data we have for now. To do this, we will merge the current dataset with a dataset that contains information about 1,000,000 movies collected from The Movie Database (TMDb), including revenue and runtime (https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset (and rename some columns)\n",
    "movies_dataset = pd.read_csv('data/tmbd_movies.csv')\n",
    "movies_dataset['box_office_revenue'] = pd.to_numeric(movies_dataset['revenue'], errors='coerce') \n",
    "movies_dataset['release_date'] = pd.to_datetime(movies_dataset['release_date'], errors='coerce')\n",
    "\n",
    "# We remove the nan of movie release date since we merge on it\n",
    "movie_data['movie_release_date'] = pd.to_datetime(movie_data['movie_release_date'], errors='coerce')\n",
    "movie_data = movie_data.dropna(subset=['movie_release_date'])\n",
    "\n",
    "movies_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"box_office_revenue\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac46c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on title) with wikidata: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on title) with wikidata: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7011b5",
   "metadata": {},
   "source": [
    "Big improvement, that's good. Let's try to improve the runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f19049",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"runtime\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Runtime results missing percentage before merge (on title) with The Movies Dataset: {before_missing:.2%}\")\n",
    "print(f\"Runtime results missing percentage after merge (on title) with The Movies Dataset: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc622e09",
   "metadata": {},
   "source": [
    "That's pretty cool too, we also want to get the IMBD ID column because we need it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, _, _ = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"imdb_id\", merge_strategy='add_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfd011",
   "metadata": {},
   "source": [
    "## Getting the rating and lead actors of movies\n",
    "\n",
    "Now we want to merge with the IMDb datasets (https://developer.imdb.com/non-commercial-datasets/) in order to obtain ratings and lead actors. We consider an actor to be a lead actor if their ordering is 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb ratings and select relevant columns\n",
    "imdb_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "imdb_ratings = imdb_ratings.rename(columns={'tconst': 'imdb_id'})\n",
    "imdb_ratings = imdb_ratings[['imdb_id', 'averageRating', 'numVotes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb names data for actors\n",
    "imdb_names = pd.read_csv('data/name.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c549c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold chunks of filtered lead actors\n",
    "filtered_lead_actors = []\n",
    "\n",
    "# Process imdb_principals in chunks to reduce memory usage\n",
    "for chunk in pd.read_csv('data/title.principals.tsv', sep='\\t', chunksize=100000):\n",
    "    # Filter for lead actors (first and second-billed actor or actress)\n",
    "    chunk_lead_actors = chunk[\n",
    "        (chunk['category'].isin(['actor', 'actress'])) & \n",
    "        (chunk['ordering'].isin([1, 2]))\n",
    "    ][['tconst', 'nconst', 'ordering']]\n",
    "    \n",
    "    # Append the filtered chunk to the list\n",
    "    filtered_lead_actors.append(chunk_lead_actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all filtered chunks into a single DataFrame\n",
    "lead_actors = pd.concat(filtered_lead_actors)\n",
    "\n",
    "# Rename columns and merge with imdb_names DataFrame to get actor names\n",
    "lead_actors = lead_actors.rename(columns={'tconst': 'imdb_id'})\n",
    "lead_actors = lead_actors.merge(imdb_names[['nconst', 'primaryName']], on='nconst', how='left')\n",
    "\n",
    "# Pivot to get separate columns for the first and second lead actors\n",
    "lead_actors = lead_actors.pivot(index='imdb_id', columns='ordering', values='primaryName').reset_index()\n",
    "lead_actors.columns = ['imdb_id', 'lead_actor_1', 'lead_actor_2']\n",
    "\n",
    "# Merge movies_wikidata_merged_imdbid with IMDb ratings\n",
    "imdb_merged_movie_data = pd.merge(movie_data_merged, imdb_ratings, on='imdb_id', how='left')\n",
    "\n",
    "# Merge with lead actors data\n",
    "merged_movie_data = imdb_merged_movie_data.merge(lead_actors, on='imdb_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movie_data = merged_movie_data.drop_duplicates(subset=['imdb_id'])\n",
    "merged_movie_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d15017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {merged_movie_data.shape[0]} rows in our merged movies dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db28a2",
   "metadata": {},
   "source": [
    "## Cleaning and removing outliers\n",
    "\n",
    "Before analyzing the data any further, let's remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9903b82",
   "metadata": {},
   "source": [
    "### Character dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facc89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dob and movie_release_date to date\n",
    "character_data.loc[:, \"actor_dob\"] = pd.to_datetime(character_data[\"actor_dob\"], errors='coerce')\n",
    "character_data.loc[:, \"movie_release_date\"] = pd.to_datetime(character_data[\"movie_release_date\"], errors='coerce')\n",
    "\n",
    "\n",
    "# Create a mask for cases where `actor_dob` and `movie_release_date` are present but `actor_age_at_release` is missing\n",
    "missing_age_cases = character_data['actor_age_at_release'].isna() & \\\n",
    "                    character_data['actor_dob'].notna() & \\\n",
    "                    character_data['movie_release_date'].notna()\n",
    "# Do some of this cases exist?\n",
    "print(f\"before adding ages: {character_data.loc[:,\"actor_age_at_release\"].isnull().count()}\")\n",
    "print(missing_age_cases.any())\n",
    "print(f\"This amount of ages can be retrieved through calculation:{character_data.loc[missing_age_cases,:].shape[0]}\")\n",
    "\n",
    "# In this case we can calculate the actor age at release\n",
    "for i in character_data[missing_age_cases].index:\n",
    "    character_data.loc[i,'actor_age_at_release']=character_data.loc[i,'movie_release_date'].year - character_data.loc[i,'actor_dob'].year\n",
    "print(f\"after adding ages: {character_data[\"actor_age_at_release\"].isna().count()}\")\n",
    "character_data.loc[missing_age_cases,\"actor_age_at_release\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only non-NaN values for all columns\n",
    "columns_names = ['actor_height', 'actor_age_at_release', 'actor_gender', \n",
    "                 'actor_ethnicity_label', 'character_name', 'actor_dob']\n",
    "character_data_cleaned, reduction = keep_only_non_nans(character_data, columns_names)\n",
    "\n",
    "print(f\"Removing NaN reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fceddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid heights (between 1.5 and 2.8 meters)\n",
    "character_data_valid_heights, reduction = filter_attribute(character_data_cleaned, 'actor_height', 1.5, 2.8)\n",
    "\n",
    "print(f\"Removing invalid actor heights reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2568b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid ages (between 0 and 100 years)\n",
    "character_data_valid_ages, reduction = filter_attribute(character_data_valid_heights, 'actor_age_at_release', 0, 100)\n",
    "\n",
    "print(f\"Removing invalid actor ages reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only ethnicity labels that are common\n",
    "min_occurrence = 10\n",
    "ethnicity_label_counts = character_data_valid_ages['actor_ethnicity_label'].value_counts()\n",
    "ethnicity_labels = ethnicity_label_counts[ethnicity_label_counts > min_occurrence]\n",
    "\n",
    "mask = character_data_valid_ages['actor_ethnicity_label'].isin(ethnicity_labels.index)\n",
    "character_data_valid = character_data_valid_ages[mask]\n",
    "\n",
    "reduction = compute_reduction(character_data_valid_ages, character_data_valid)\n",
    "\n",
    "print(f\"Removing ethnicity labels which are uncommon reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final dataset size\n",
    "print(f\"Number of characters after preprocessing: {character_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "character_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e02989",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "\n",
    "We will also remove the outliers and preprocess the movie dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e727d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated columns\n",
    "movie_data_extracted = merged_movie_data.drop(columns=['title', 'release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lead_actor_2 to NaN where it is the same as lead_actor_1\n",
    "movie_data_extracted.loc[movie_data_extracted['lead_actor_1'] == movie_data_extracted['lead_actor_2'], 'lead_actor_2'] = pd.NA\n",
    "\n",
    "# Remove movies where we don't have lead actor\n",
    "movie_data_extracted = movie_data_extracted.dropna(subset=['lead_actor_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6268dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only non-NaN values for all columns (the other columns have no missing values)\n",
    "columns_names = ['movie_release_date', 'runtime', 'languages', 'countries', \n",
    "                 'genres', 'lead_actor_1', 'box_office_revenue', 'averageRating']\n",
    "movie_data_cleaned, reduction = keep_only_non_nans(movie_data_extracted, columns_names)\n",
    "\n",
    "print(f\"Removing NaN reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a768ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only movies released after 1940\n",
    "movie_data_valid_release_dates = movie_data_cleaned[movie_data_cleaned[\"movie_release_date\"]>'1-1-1940']\n",
    "\n",
    "reduction = compute_reduction(movie_data_cleaned, movie_data_valid_release_dates)\n",
    "print(f\"Removing movies released before 1940 reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ad5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only movies that last between 1h and 200min\n",
    "movie_data_valid_runtime, reduction = filter_attribute(movie_data_valid_release_dates, 'runtime', 60, 200)\n",
    "print(f\"Removing movies lasting less than 1h or more than 3 hours 20mins reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e3e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only movies that have at least 500 votes\n",
    "movie_data_valid_votes = movie_data_valid_runtime[movie_data_valid_runtime[\"numVotes\"]>500]\n",
    "\n",
    "reduction = compute_reduction(movie_data_valid_runtime, movie_data_valid_votes)\n",
    "print(f\"Removing movies that have less than 500 votes: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only movies that have more than 0 box office revenue\n",
    "movie_data_valid_revenue = movie_data_valid_votes[movie_data_valid_votes[\"box_office_revenue\"]>0]\n",
    "\n",
    "reduction = compute_reduction(movie_data_valid_votes, movie_data_valid_revenue)\n",
    "print(f\"Removing movies that have no box office revenue: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_valid = movie_data_valid_revenue.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0252f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of movies after preprocessing: {movie_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "movie_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893cdd2",
   "metadata": {},
   "source": [
    "## Do we have data for the lead actors\n",
    "\n",
    "Now that we have the two main actors of each movie, let's see if we have their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique pairs of (freebase_movie_id, lead_actor) from the movie dataset\n",
    "lead_actor_pairs = pd.concat([\n",
    "    movie_data_valid[['freebase_movie_id', 'lead_actor_1']].rename(columns={'lead_actor_1': 'actor_name'}),\n",
    "    movie_data_valid[['freebase_movie_id', 'lead_actor_2']].rename(columns={'lead_actor_2': 'actor_name'})\n",
    "])\n",
    "\n",
    "# Convert the DataFrame of pairs to a list of tuples for filtering\n",
    "lead_actor_pairs = list(lead_actor_pairs.itertuples(index=False, name=None))\n",
    "\n",
    "# Filter character_data to keep only rows where (freebase_movie_id, actor_name) matches the pairs in lead_actor_pairs\n",
    "lead_actor_data = character_data_valid[\n",
    "    character_data_valid[['freebase_movie_id', 'actor_name']].apply(tuple, axis=1).isin(lead_actor_pairs)\n",
    "]\n",
    "\n",
    "# Check for missing values in key columns\n",
    "print(\"Missing values in lead actor data:\")\n",
    "print(lead_actor_data[['actor_name', 'actor_dob', 'actor_gender', 'actor_ethnicity', 'actor_height', 'actor_age_at_release']].isna().mean()*100)\n",
    "\n",
    "# Display the first few rows of the filtered data\n",
    "lead_actor_data.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653bfc3",
   "metadata": {},
   "source": [
    "This make sense since we preprocessed our character data, let's now see if we have data for all of our actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have data for {lead_actor_data.shape[0]/(movie_data_valid[\"lead_actor_1\"].notna().sum() + movie_data_valid[\"lead_actor_2\"].notna().sum())*100}% ({lead_actor_data.shape[0]} actors) of our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be30b0",
   "metadata": {},
   "source": [
    "Ok good, let's now create a subset dataframe that will contains only the movies for which we have data on the lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd31290",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_movies_with_lead_actors_data = movie_data_valid[movie_data_valid['freebase_movie_id'].isin(lead_actor_data['freebase_movie_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_movies_with_lead_actors_data.shape[0]} movies for which we have full data on our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34957642",
   "metadata": {},
   "source": [
    "We can also extract the characters that are part of this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the character_data_valid dataset to keep only rows with freebase_movie_id present in movie_data_extracted\n",
    "subset_characters_with_lead_actor_data = character_data_valid[character_data_valid['freebase_movie_id'].isin(subset_movies_with_lead_actors_data['freebase_movie_id'])]\n",
    "\n",
    "# Extract the relevant columns for characters and associated movies\n",
    "subset_characters_with_lead_actor_data = subset_characters_with_lead_actor_data[['actor_name', 'actor_dob', 'actor_gender', 'actor_ethnicity', 'actor_height', 'actor_age_at_release', 'freebase_movie_id', 'character_name']]\n",
    "\n",
    "# Display the first few rows of the filtered and extracted data\n",
    "subset_characters_with_lead_actor_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_characters_with_lead_actor_data.shape[0]} characters for the subset movies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56351b7",
   "metadata": {},
   "source": [
    "## Saving our newly created dataframes\n",
    "\n",
    "We will save our five dataframes:\n",
    "\n",
    "- full_movie_data_preprocessed that contains all the movies preprocessed \n",
    "- full_characters_data_preprocessed that contains all the characters preprocessed\n",
    "- subset_movies_with_lead_actors_data that contains movies where we have data on all the lead actors\n",
    "- lead_actors_data_on_subset_movie that contains information on the lead actors of the previous subset\n",
    "- character_data_valid_filtered that contains information on all the characters of the previous subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_path = 'data/preprocessed'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(preprocessed_path, exist_ok=True)\n",
    "\n",
    "preprocessed_names = {\n",
    "    'full_movie_data_preprocessed.csv': movie_data_valid,\n",
    "    'full_characters_data_preprocessed.csv': character_data_valid,\n",
    "    'subset_movie_with_full_data_on_lead_actors.csv': subset_movies_with_lead_actors_data,\n",
    "    'lead_actors_data_on_subset_movie.csv': lead_actor_data,\n",
    "    'characters_data_on_subset_movie.csv': subset_characters_with_lead_actor_data\n",
    "}\n",
    "\n",
    "for name, df in preprocessed_names.items():\n",
    "    df.to_csv(os.path.join(preprocessed_path, name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356afe5",
   "metadata": {},
   "source": [
    "## Loading our preprocessed dataframes\n",
    "\n",
    "We can skip all the preprocessing process and load our dataframes directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed datasets\n",
    "full_movie_data_preprocessed = pd.read_csv('data/preprocessed/full_movie_data_preprocessed.csv')\n",
    "full_characters_data_preprocessed = pd.read_csv('data/preprocessed/full_characters_data_preprocessed.csv')\n",
    "subset_movie_with_full_data_on_lead_actors = pd.read_csv('data/preprocessed/subset_movie_with_full_data_on_lead_actors.csv')\n",
    "lead_actors_data_on_subset_movie = pd.read_csv('data/preprocessed/lead_actors_data_on_subset_movie.csv')\n",
    "characters_data_on_subset_movie = pd.read_csv('data/preprocessed/characters_data_on_subset_movie.csv')\n",
    "\n",
    "# We must convert dates to datetime\n",
    "lead_actors_data_on_subset_movie['actor_dob'] = pd.to_datetime(lead_actors_data_on_subset_movie['actor_dob'])\n",
    "characters_data_on_subset_movie['actor_dob'] = pd.to_datetime(characters_data_on_subset_movie['actor_dob'])\n",
    "full_movie_data_preprocessed['movie_release_date'] = pd.to_datetime(full_movie_data_preprocessed['movie_release_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab0a23",
   "metadata": {},
   "source": [
    "## Deeper analysis\n",
    "Now that our data is more complete, we can do a more in deep analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951bc2b",
   "metadata": {},
   "source": [
    "### Lead actors dataset \n",
    "\n",
    "Let's first analyze our dataframe with the lead actors just created. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_actors_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74caf699",
   "metadata": {},
   "source": [
    "Let's print their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the height of actors\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_height\", bins=25, ax=axes[0], kde=False)\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "\n",
    "# Histogram for the actors' age at release\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], kde=True)\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2], kde=True)\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067ac33",
   "metadata": {},
   "source": [
    "Let's now lets explore the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Countplot for the gender distribution\n",
    "sns.countplot(data=lead_actors_data_on_subset_movie, x=\"actor_gender\", ax=axes[0], stat='proportion')\n",
    "axes[0].set_title(\"Actor gender distribution\")\n",
    "axes[0].set_xlabel(\"Gender\")\n",
    "axes[0].set_ylabel(\"Proportion\")\n",
    "\n",
    "ethnicity_cutoff = 30\n",
    "values = lead_actors_data_on_subset_movie[\"actor_ethnicity_label\"].value_counts()\n",
    "values = values[:ethnicity_cutoff]\n",
    "sns.barplot(x=values, y=values.index, ax=axes[1])\n",
    "axes[1].set_title(f\"{ethnicity_cutoff} most common ethnicity label\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Ethnicity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d287f74",
   "metadata": {},
   "source": [
    "We can visualize here the correlation matrix between the numerical attributes of the actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d94a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "lead_actors_for_corr = lead_actors_data_on_subset_movie[['actor_height', 'actor_age_at_release','actor_gender' ]]\n",
    "# Convert gender to boolean by getting dummies\n",
    "lead_actors_gender_dummies = pd.get_dummies(lead_actors_for_corr['actor_gender'])\n",
    "lead_actors_for_corr.drop('actor_gender', axis=1, inplace=True)\n",
    "lead_actors_for_corr = lead_actors_for_corr.join(lead_actors_gender_dummies)\n",
    "# lead_actors_for_corr['F'] = lead_actors_gender_dummies['F']\n",
    "# lead_actors_for_corr['M'] = lead_actors_gender_dummies['M']\n",
    "corr_matrix = lead_actors_for_corr.corr()\n",
    "label_names = ['Height', 'Age at release']\n",
    "ax = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', xticklabels=label_names, yticklabels=label_names)\n",
    "ax.set_title('Heatmap of some actors attributes');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7792b",
   "metadata": {},
   "source": [
    "### Movies dataset \n",
    "\n",
    "Let's now analyse our movies dataset. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_completed = full_movie_data_preprocessed.copy()\n",
    "movie_data_completed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9a852",
   "metadata": {},
   "source": [
    "Let's print their distributions (except for the wikipedia id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "sns.histplot(data=movie_data_completed, x=\"runtime\", bins=50, ax=axes[0], kde=True)\n",
    "axes[0].set_title(\"Histogram for runtime\")\n",
    "axes[0].set_xlabel(\"Runtime (min)\")\n",
    "\n",
    "# Histogram for the box office results\n",
    "sns.histplot(data=movie_data_completed, x=\"box_office_revenue\", bins=50, ax=axes[1], kde=True, log_scale=True)\n",
    "axes[1].set_title(\"Histogram for the box office revenue\")\n",
    "axes[1].set_xlabel(\"Box office revenue (dollars, log scale)\")\n",
    "\n",
    "\n",
    "# Histogram for the release date\n",
    "sns.histplot(data=movie_data_completed, x=\"movie_release_date\", bins=50, ax=axes[2], kde=False)\n",
    "axes[2].set_title(\"Histogram for the release date\")\n",
    "axes[2].set_xlabel(\"Release date\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c2eb7",
   "metadata": {},
   "source": [
    "Let's now look at the ratings and number of votes per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the movie ratings\n",
    "rating_intervals = np.arange(0, 11, 1)\n",
    "sns.histplot(data=movie_data_completed, x=\"averageRating\", bins=rating_intervals, ax=axes[0])\n",
    "\n",
    "axes[0].set_xlabel('Rating intervals')\n",
    "axes[0].set_xticks(rating_intervals)\n",
    "axes[0].set_title('Histogram for movie ratings')\n",
    "\n",
    "# Histogram for the number of votes\n",
    "sns.histplot(data=movie_data_completed, x=\"numVotes\", bins=50, ax=axes[1], kde=True, log_scale=True)\n",
    "\n",
    "axes[1].set_xlabel('Number of votes (log scale)')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_title('Histogram for number of votes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_completed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfe28f",
   "metadata": {},
   "source": [
    "We can now have a look at the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "cutoff = 20 \n",
    "\n",
    "# Flatten the columns containing the lists of languages\n",
    "movie_languages_flat = movie_data_completed['languages'].apply(eval).explode()\n",
    "values = movie_languages_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "\n",
    "# Barplot for the languages distribution\n",
    "sns.barplot(x=values, y=values.index, ax=axes[0])\n",
    "axes[0].set_title(f\"{cutoff} most common languages\")\n",
    "axes[0].set_xlabel(\"Count\")\n",
    "axes[0].set_ylabel(\"Language\")\n",
    "\n",
    "# Flatten the columns containing the lists of countries\n",
    "movie_countries_flat = movie_data_completed['countries'].apply(eval).explode()\n",
    "values = movie_countries_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "\n",
    "# Barplot for the countries distribution\n",
    "sns.barplot(x=values, y=values.index, ax=axes[1])\n",
    "axes[1].set_title(f\"{cutoff} most common countries\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Country\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95a393",
   "metadata": {},
   "source": [
    "As we can expect, the English language and United States of America clearly dominate the movie industry.\n",
    "\n",
    "Let's now look at the most common genres that appear in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_cutoff = 30\n",
    "\n",
    "# Flatten the columns containing the lists of genres\n",
    "movie_genres_flat = movie_data_completed['genres'].apply(eval).explode()\n",
    "values = movie_genres_flat.value_counts()\n",
    "values = values[:genres_cutoff]\n",
    "\n",
    "# Countplot for the languages distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(x=values, y=values.index, ax=ax)\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Genres')\n",
    "ax.set_title(f'{genres_cutoff} most common genres');\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f48297",
   "metadata": {},
   "source": [
    "### Characters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceeae5f",
   "metadata": {},
   "source": [
    "We now analyze the dataframe with the characters (including non-lead actors). We again start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff57aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c2f07",
   "metadata": {},
   "source": [
    "Let's do some plots to visualize better. As it is very similar as the plots from the lead actors dataset, we will compare our plots with the ones from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ab151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label variables to ensure uniform legends in the plots\n",
    "label_all = \"All actors\"\n",
    "label_lead = \"Lead actors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the height of actors\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_height\", bins=25, ax=axes[0], \n",
    "             kde=False, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_height\", bins=25, \n",
    "             ax=axes[0], kde=False, stat='percent', label=label_lead)\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogram for the age of actors at release\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], \n",
    "             kde=True, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], \n",
    "             kde=True, stat='percent', label=label_lead)\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2], \n",
    "             kde=True, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2],\n",
    "             kde=True, stat='percent', label=label_lead)\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2ecd5",
   "metadata": {},
   "source": [
    "Finally we compare the gender distribution between all actors and only lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556887b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "width = 0.4\n",
    "\n",
    "gender_dist_all = characters_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "gender_dist_lead = lead_actors_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "labels = list(gender_dist_all.keys())\n",
    "\n",
    "bar_all = ax.bar(labels, gender_dist_all, -width, label=label_all, align='edge')\n",
    "bar_lead = ax.bar(labels, gender_dist_lead, width, label=label_lead, align='edge')\n",
    "\n",
    "ax.set_title(\"Comparison of actors' gender distribution between lead roles and all roles\")\n",
    "ax.set_xlabel(\"Gender\")\n",
    "ax.set_ylabel(\"Percent\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d49597",
   "metadata": {},
   "source": [
    "### Regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66074dbc",
   "metadata": {},
   "source": [
    "Let's see if we can predict the box office from the average rating and the number of votes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04858c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the box office revenue that is greater than 0\n",
    "valid_box_office = full_movie_data_preprocessed[\"box_office_revenue\"] > 0\n",
    "full_movie_data_preprocessed = full_movie_data_preprocessed[valid_box_office]\n",
    "\n",
    "# Take the log of the box office revenue and of numVotes\n",
    "full_movie_data_preprocessed[\"log_box_office_revenue\"] = np.log(full_movie_data_preprocessed[\"box_office_revenue\"])\n",
    "full_movie_data_preprocessed[\"log_numVotes\"] = np.log(full_movie_data_preprocessed[\"numVotes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13950c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model formula\n",
    "mod = smf.ols(formula='log_box_office_revenue ~ averageRating + log_numVotes', data=full_movie_data_preprocessed)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Fit the model\n",
    "res = mod.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851ebdc",
   "metadata": {},
   "source": [
    "Interesting, there is a strong positive corelation between the number of votes and the box office revenue.\n",
    "Let's visualize this in a scatter plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=full_movie_data_preprocessed, x='averageRating', y='log_numVotes', hue='log_box_office_revenue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
