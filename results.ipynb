{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddaee4c",
   "metadata": {},
   "source": [
    "# CMU Movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b837b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "from src.data_completion import *\n",
    "from src.data_preprocessing import *\n",
    "from src.data_loading import *\n",
    "from src.data_fetching import *\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8ac0f",
   "metadata": {},
   "source": [
    "## Downloading datasets\n",
    "The following code dowloads the datasets that were too heavy to be included, and places them directly in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d88e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download TMDb Dataset\n",
    "download_tmdb()\n",
    "\n",
    "#Download IMDb Dataset\n",
    "download_imdb(\"name.basics.tsv\")\n",
    "download_imdb(\"title.ratings.tsv\")\n",
    "download_imdb(\"title.principals.tsv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5340b",
   "metadata": {},
   "source": [
    "## Initial data inspection\n",
    "We will first try to provide a first generic inspection of the CMU movie dataset we decided to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f50aa3",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "The dataset is divided in 3 parts, the characters, the movies and the plots of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9ee11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data, movie_data, plot_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd05ad",
   "metadata": {},
   "source": [
    "### Characters dataset\n",
    "Let's first have a look to the character dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b789d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {character_data.shape[0]} characters with {character_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72305a3",
   "metadata": {},
   "source": [
    "We directly note that the actor ethnicities are not human readable, they look to be freebase ids. It's something we will need to fix during preprocessing.\n",
    "Let's now see how much missing data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec456244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the characters dataset for each features:\")\n",
    "print(character_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2afd6",
   "metadata": {},
   "source": [
    "We see that we miss a lot of character names/ids, actor heights, ethnicity and age at release. We can also check for duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec919b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {character_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4be89",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "Let's now have a look at the movies dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af339272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {movie_data.shape[0]} movies with {movie_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a5ea",
   "metadata": {},
   "source": [
    "Let's now see if we have a lot of missing data. We will also verify that we don't have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82985100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the movies dataset for each features:\")\n",
    "print(movie_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465283a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {movie_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71496d7e",
   "metadata": {},
   "source": [
    "Ouch! We only have box office revenue for 10% of our movies, that's not good news since it's a key feature in our research problematic, we will need to fix this. Apart from this, we can also note that we are missing 25% of the runtime information. We could try to improve this. This also applies to the movie release data. For the languages, countries and genres, we note that they are dictionaries meaning that we first need to preprocess them a bit (for example transforming them to a list) to then be able to see the percentage of missing data. We will do it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e89dd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the readable values for 'languages', 'countries', and 'genres' columns. Also clean the language column.\n",
    "\n",
    "movie_data['languages'] = movie_data['languages'].apply(lambda x: extract_values(x, clean_func=clean_language))\n",
    "movie_data['countries'] = movie_data['countries'].apply(lambda x: extract_values(x)) \n",
    "movie_data['genres'] = movie_data['genres'].apply(lambda x: extract_values(x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f611732",
   "metadata": {},
   "source": [
    "We can now have a look to the missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of None (NaN) values for each column\n",
    "none_languages = movie_data['languages'].isna().mean()\n",
    "none_countries = movie_data['countries'].isna().mean()\n",
    "none_genres = movie_data['genres'].isna().mean()\n",
    "\n",
    "# Print the counts of None (NaN) values\n",
    "print(f\"Percentage of None values in 'languages': {none_languages:.2%}\")\n",
    "print(f\"Percentage of None values in 'countries': {none_countries:.2%}\")\n",
    "print(f\"Percentage of None values in 'genres': {none_genres:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6999f",
   "metadata": {},
   "source": [
    "We miss some data but nothing too huge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ee937",
   "metadata": {},
   "source": [
    "### Plot summary dataset\n",
    "Let's now have a look at the plot summaries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {plot_data.shape[0]} plot summaries with {plot_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f05e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec2b3e",
   "metadata": {},
   "source": [
    "Let's see if we have some rows that are invalid (no summary or wikipedia id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead77807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pourcentage of null rows in the plot summaries dataset:\")\n",
    "print(plot_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353cf7c",
   "metadata": {},
   "source": [
    "Good new, we have nothing missing here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5a1f3",
   "metadata": {},
   "source": [
    "## Data completion\n",
    "\n",
    "### Missing data\n",
    "Before going deeper to the analysis, we want to already fix the fact that we are missing data for most of the box office results and some runtime values.\n",
    "\n",
    "Let's then first to get more data on box office results to decrease the number of missing data we have for now. To do this, we will merge the current dataset with a dataset that contains information about 1,000,000 movies collected from The Movie Database (TMDb), including revenue and runtime (https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset (and rename some columns)\n",
    "movies_dataset = pd.read_csv('data/tmbd_movies.csv')\n",
    "movies_dataset['box_office_revenue'] = pd.to_numeric(movies_dataset['revenue'], errors='coerce') \n",
    "movies_dataset['release_date'] = pd.to_datetime(movies_dataset['release_date'], errors='coerce')\n",
    "\n",
    "# We remove the nan of movie release date since we merge on it\n",
    "movie_data['movie_release_date'] = pd.to_datetime(movie_data['movie_release_date'], errors='coerce')\n",
    "movie_data = movie_data.dropna(subset=['movie_release_date'])\n",
    "\n",
    "movies_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b31cb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"box_office_revenue\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac46c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on title) with wikidata: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on title) with wikidata: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7011b5",
   "metadata": {},
   "source": [
    "Big improvement, that's good. Let's try to improve the runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1f19049",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"runtime\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Runtime results missing percentage before merge (on title) with The Movies Dataset: {before_missing:.2%}\")\n",
    "print(f\"Runtime results missing percentage after merge (on title) with The Movies Dataset: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc622e09",
   "metadata": {},
   "source": [
    "That's pretty cool too, we also want to merge the IMBD ID column because we need it afterwards (and we don't have it with the CMU dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f9b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, _, _ = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"imdb_id\", merge_strategy='add_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfd011",
   "metadata": {},
   "source": [
    "### Adding the rating and lead actors of movies\n",
    "\n",
    "Now we want to merge with the IMDb datasets (https://developer.imdb.com/non-commercial-datasets/) in order to obtain ratings and lead actors. We consider an actor to be a lead actor if their ordering is 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c732165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb ratings and select relevant columns\n",
    "imdb_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "imdb_ratings = imdb_ratings.rename(columns={'tconst': 'imdb_id'})\n",
    "imdb_ratings = imdb_ratings[['imdb_id', 'averageRating', 'numVotes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8cc45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb names data for actors\n",
    "imdb_names = pd.read_csv('data/name.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c549c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract lead actors (representing the first and second roles)\n",
    "filtered_lead_actors = extract_lead_actors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the lead actors into movie data\n",
    "movie_data_merged = merge_lead_actors_and_ratings(movie_data_merged, imdb_names, imdb_ratings, filtered_lead_actors)\n",
    "movie_data_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d15017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {movie_data_merged.shape[0]} rows in our merged movies dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db28a2",
   "metadata": {},
   "source": [
    "## Cleaning and removing outliers\n",
    "\n",
    "Before analyzing the data any further, let's clean our data and remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9903b82",
   "metadata": {},
   "source": [
    "### Character dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8438f2",
   "metadata": {},
   "source": [
    "First thing we want to do is to make our ethnicites human readable. To do it we used the wikidata API to map the IDs. We created a CSV file to avoid making multiple request each time we run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_character_data = map_ethnicities(character_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9ceea",
   "metadata": {},
   "source": [
    "We can now do more basic preprocessing. For more details, please have a look to our function in src/data_preprocessing.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data_valid = preprocess_characters(merged_character_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final dataset size\n",
    "print(f\"Number of characters after preprocessing: {character_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "character_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae88aa",
   "metadata": {},
   "source": [
    "This is good. We don't care about the movie_release_date here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e02989",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "\n",
    "We will also remove the outliers and preprocess the movie dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_valid = preprocess_movies(movie_data_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0252f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of movies after preprocessing: {movie_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "movie_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33d6f9",
   "metadata": {},
   "source": [
    "That looks perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893cdd2",
   "metadata": {},
   "source": [
    "## Movies subset creation with complete lead actors data \n",
    "\n",
    "Now that we have the two main actors of each movie, let's see if we have corresponding characteristics in the preprocessed character dataset. First we will extract the characters data of all our lead actors in all our films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_actor_data = extract_movies_with_lead_actors_data(movie_data_valid, character_data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653bfc3",
   "metadata": {},
   "source": [
    "No missing value makes sense since we preprocessed our character data. Let's try now to see how much data we have on our lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have data for {lead_actor_data.shape[0]/(movie_data_valid[\"lead_actor_1\"].notna().sum() + movie_data_valid[\"lead_actor_2\"].notna().sum())*100}% ({lead_actor_data.shape[0]} actors) of our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be30b0",
   "metadata": {},
   "source": [
    "Ok good, let's now create a subset dataframe that will contains only the movies for which we have complete data on the lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1dd31290",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_movies_with_lead_actors_data = movie_data_valid[movie_data_valid['freebase_movie_id'].isin(lead_actor_data['freebase_movie_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_movies_with_lead_actors_data.shape[0]} movies for which we have full data on our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34957642",
   "metadata": {},
   "source": [
    "Now that we have this movies subset, we can extract the corresponding lead actors and characters subsets for these movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the character_data_valid dataset to keep only rows with freebase_movie_id present in movie_data_extracted\n",
    "subset_characters_with_lead_actor_data = character_data_valid[character_data_valid['freebase_movie_id'].isin(subset_movies_with_lead_actors_data['freebase_movie_id'])]\n",
    "\n",
    "# Extract the relevant columns for characters and associated movies\n",
    "subset_characters_with_lead_actor_data = subset_characters_with_lead_actor_data[['actor_name', 'actor_dob', 'actor_gender', 'actor_ethnicity_label', 'actor_height', 'actor_age_at_release', 'freebase_movie_id', 'character_name']]\n",
    "\n",
    "# Display the first few rows of the filtered and extracted data\n",
    "subset_characters_with_lead_actor_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_characters_with_lead_actor_data.shape[0]} characters for the movies subset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_lead_actors = extract_movies_with_lead_actors_data(subset_movies_with_lead_actors_data, character_data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77311f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_lead_actors.shape[0]} lead actors for the movies subset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56351b7",
   "metadata": {},
   "source": [
    "## Saving our newly created dataframes\n",
    "\n",
    "We will save our five dataframes:\n",
    "\n",
    "- full_movie_data_preprocessed that contains all the movies preprocessed \n",
    "- full_characters_data_preprocessed that contains all the characters preprocessed\n",
    "- subset_movies_with_lead_actors_data that contains movies where we have data on all the lead actors\n",
    "- lead_actors_data_on_subset_movie that contains information on the lead actors of the previous subset\n",
    "- character_data_valid_filtered that contains information on all the characters of the previous subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf9f7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_path = 'data/preprocessed'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(preprocessed_path, exist_ok=True)\n",
    "\n",
    "preprocessed_names = {\n",
    "    'full_movie_data_preprocessed.csv': movie_data_valid,\n",
    "    'full_characters_data_preprocessed.csv': character_data_valid,\n",
    "    'subset_movie_with_full_data_on_lead_actors.csv': subset_movies_with_lead_actors_data,\n",
    "    'lead_actors_data_on_subset_movie.csv': subset_lead_actors,\n",
    "    'characters_data_on_subset_movie.csv': subset_characters_with_lead_actor_data\n",
    "}\n",
    "\n",
    "for name, df in preprocessed_names.items():\n",
    "    df.to_csv(os.path.join(preprocessed_path, name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356afe5",
   "metadata": {},
   "source": [
    "## Loading our preprocessed dataframes\n",
    "\n",
    "We can skip all the preprocessing process and load our dataframes directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed datasets\n",
    "full_movie_data_preprocessed = pd.read_csv('data/preprocessed/full_movie_data_preprocessed.csv')\n",
    "full_characters_data_preprocessed = pd.read_csv('data/preprocessed/full_characters_data_preprocessed.csv')\n",
    "subset_movie_with_full_data_on_lead_actors = pd.read_csv('data/preprocessed/subset_movie_with_full_data_on_lead_actors.csv')\n",
    "lead_actors_data_on_subset_movie = pd.read_csv('data/preprocessed/lead_actors_data_on_subset_movie.csv')\n",
    "characters_data_on_subset_movie = pd.read_csv('data/preprocessed/characters_data_on_subset_movie.csv')\n",
    "\n",
    "# We must convert dates to datetime\n",
    "lead_actors_data_on_subset_movie['actor_dob'] = pd.to_datetime(lead_actors_data_on_subset_movie['actor_dob'])\n",
    "characters_data_on_subset_movie['actor_dob'] = pd.to_datetime(characters_data_on_subset_movie['actor_dob'])\n",
    "full_movie_data_preprocessed['movie_release_date'] = pd.to_datetime(full_movie_data_preprocessed['movie_release_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab0a23",
   "metadata": {},
   "source": [
    "## Deeper analysis\n",
    "Now that our data is more complete, we can do a more in deep analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951bc2b",
   "metadata": {},
   "source": [
    "### Lead actors dataset \n",
    "\n",
    "Let's first analyze our dataframe with the lead actors just created. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_actors_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74caf699",
   "metadata": {},
   "source": [
    "Let's print their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the height of actors\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_height\", bins=25, ax=axes[0], kde=False)\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "\n",
    "# Histogram for the actors' age at release\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], kde=True)\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2], kde=True)\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067ac33",
   "metadata": {},
   "source": [
    "Let's now lets explore the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Countplot for the gender distribution\n",
    "sns.countplot(data=lead_actors_data_on_subset_movie, x=\"actor_gender\", ax=axes[0], stat='proportion')\n",
    "axes[0].set_title(\"Actor gender distribution\")\n",
    "axes[0].set_xlabel(\"Gender\")\n",
    "axes[0].set_ylabel(\"Proportion\")\n",
    "\n",
    "ethnicity_cutoff = 30\n",
    "values = lead_actors_data_on_subset_movie[\"actor_ethnicity_label\"].value_counts()\n",
    "values = values[:ethnicity_cutoff]\n",
    "sns.barplot(x=values, y=values.index, ax=axes[1])\n",
    "axes[1].set_title(f\"{ethnicity_cutoff} most common ethnicity label\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Ethnicity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d287f74",
   "metadata": {},
   "source": [
    "We can visualize here the correlation matrix between the numerical attributes of the actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d94a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "lead_actors_for_corr = lead_actors_data_on_subset_movie[['actor_height', 'actor_age_at_release','actor_gender' ]]\n",
    "# Convert gender to boolean by getting dummies\n",
    "lead_actors_gender_dummies = pd.get_dummies(lead_actors_for_corr['actor_gender'])\n",
    "lead_actors_for_corr.drop('actor_gender', axis=1, inplace=True)\n",
    "lead_actors_for_corr = lead_actors_for_corr.join(lead_actors_gender_dummies)\n",
    "# lead_actors_for_corr['F'] = lead_actors_gender_dummies['F']\n",
    "# lead_actors_for_corr['M'] = lead_actors_gender_dummies['M']\n",
    "corr_matrix = lead_actors_for_corr.corr()\n",
    "label_names = ['Height', 'Age at release']\n",
    "ax = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', xticklabels=label_names, yticklabels=label_names)\n",
    "ax.set_title('Heatmap of some actors attributes');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7792b",
   "metadata": {},
   "source": [
    "### Movies dataset \n",
    "\n",
    "Let's now analyse our movies dataset. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_completed = full_movie_data_preprocessed.copy()\n",
    "movie_data_completed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9a852",
   "metadata": {},
   "source": [
    "Let's print their distributions (except for the wikipedia id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "sns.histplot(data=movie_data_completed, x=\"runtime\", bins=50, ax=axes[0], kde=True)\n",
    "axes[0].set_title(\"Histogram for runtime\")\n",
    "axes[0].set_xlabel(\"Runtime (min)\")\n",
    "\n",
    "# Histogram for the box office results\n",
    "sns.histplot(data=movie_data_completed, x=\"box_office_revenue\", bins=50, ax=axes[1], kde=True, log_scale=True)\n",
    "axes[1].set_title(\"Histogram for the box office revenue\")\n",
    "axes[1].set_xlabel(\"Box office revenue (dollars, log scale)\")\n",
    "\n",
    "\n",
    "# Histogram for the release date\n",
    "sns.histplot(data=movie_data_completed, x=\"movie_release_date\", bins=50, ax=axes[2], kde=False)\n",
    "axes[2].set_title(\"Histogram for the release date\")\n",
    "axes[2].set_xlabel(\"Release date\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c2eb7",
   "metadata": {},
   "source": [
    "Let's now look at the ratings and number of votes per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the movie ratings\n",
    "rating_intervals = np.arange(0, 11, 1)\n",
    "sns.histplot(data=movie_data_completed, x=\"averageRating\", bins=rating_intervals, ax=axes[0])\n",
    "\n",
    "axes[0].set_xlabel('Rating intervals')\n",
    "axes[0].set_xticks(rating_intervals)\n",
    "axes[0].set_title('Histogram for movie ratings')\n",
    "\n",
    "# Histogram for the number of votes\n",
    "sns.histplot(data=movie_data_completed, x=\"numVotes\", bins=50, ax=axes[1], kde=True, log_scale=True)\n",
    "\n",
    "axes[1].set_xlabel('Number of votes (log scale)')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_title('Histogram for number of votes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_completed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfe28f",
   "metadata": {},
   "source": [
    "We can now have a look at the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "cutoff = 20 \n",
    "\n",
    "# Flatten the columns containing the lists of languages\n",
    "movie_languages_flat = movie_data_completed['languages'].apply(eval).explode()\n",
    "values = movie_languages_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "\n",
    "# Barplot for the languages distribution\n",
    "sns.barplot(x=values, y=values.index, ax=axes[0])\n",
    "axes[0].set_title(f\"{cutoff} most common languages\")\n",
    "axes[0].set_xlabel(\"Count\")\n",
    "axes[0].set_ylabel(\"Language\")\n",
    "\n",
    "# Flatten the columns containing the lists of countries\n",
    "movie_countries_flat = movie_data_completed['countries'].apply(eval).explode()\n",
    "values = movie_countries_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "\n",
    "# Barplot for the countries distribution\n",
    "sns.barplot(x=values, y=values.index, ax=axes[1])\n",
    "axes[1].set_title(f\"{cutoff} most common countries\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Country\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95a393",
   "metadata": {},
   "source": [
    "As we can expect, the English language and United States of America clearly dominate the movie industry.\n",
    "\n",
    "Let's now look at the most common genres that appear in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_cutoff = 30\n",
    "\n",
    "# Flatten the columns containing the lists of genres\n",
    "movie_genres_flat = movie_data_completed['genres'].apply(eval).explode()\n",
    "values = movie_genres_flat.value_counts()\n",
    "values = values[:genres_cutoff]\n",
    "\n",
    "# Countplot for the languages distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(x=values, y=values.index, ax=ax)\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Genres')\n",
    "ax.set_title(f'{genres_cutoff} most common genres');\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f48297",
   "metadata": {},
   "source": [
    "### Characters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceeae5f",
   "metadata": {},
   "source": [
    "We now analyze the dataframe with the characters (including non-lead actors). We again start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff57aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c2f07",
   "metadata": {},
   "source": [
    "Let's do some plots to visualize better. As it is very similar as the plots from the lead actors dataset, we will compare our plots with the ones from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ab151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label variables to ensure uniform legends in the plots\n",
    "label_all = \"All actors\"\n",
    "label_lead = \"Lead actors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the height of actors\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_height\", bins=25, ax=axes[0], \n",
    "             kde=False, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_height\", bins=25, \n",
    "             ax=axes[0], kde=False, stat='percent', label=label_lead)\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogram for the age of actors at release\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], \n",
    "             kde=True, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_age_at_release\", bins=25, ax=axes[1], \n",
    "             kde=True, stat='percent', label=label_lead)\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=characters_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2], \n",
    "             kde=True, stat='percent', label=label_all)\n",
    "sns.histplot(data=lead_actors_data_on_subset_movie, x=\"actor_dob\", bins=25, ax=axes[2],\n",
    "             kde=True, stat='percent', label=label_lead)\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2ecd5",
   "metadata": {},
   "source": [
    "Finally we compare the gender distribution between all actors and only lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556887b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "width = 0.4\n",
    "\n",
    "gender_dist_all = characters_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "gender_dist_lead = lead_actors_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "labels = list(gender_dist_all.keys())\n",
    "\n",
    "bar_all = ax.bar(labels, gender_dist_all, -width, label=label_all, align='edge')\n",
    "bar_lead = ax.bar(labels, gender_dist_lead, width, label=label_lead, align='edge')\n",
    "\n",
    "ax.set_title(\"Comparison of actors' gender distribution between lead roles and all roles\")\n",
    "ax.set_xlabel(\"Gender\")\n",
    "ax.set_ylabel(\"Percent\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d49597",
   "metadata": {},
   "source": [
    "### Regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66074dbc",
   "metadata": {},
   "source": [
    "Let's see if we can predict the box office from the average rating and the number of votes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04858c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the log of the box office revenue and of numVotes\n",
    "full_movie_data_preprocessed[\"log_box_office_revenue\"] = np.log(full_movie_data_preprocessed[\"box_office_revenue\"])\n",
    "full_movie_data_preprocessed[\"log_numVotes\"] = np.log(full_movie_data_preprocessed[\"numVotes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13950c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model formula\n",
    "mod = smf.ols(formula='log_box_office_revenue ~ averageRating + log_numVotes', data=full_movie_data_preprocessed)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Fit the model\n",
    "res = mod.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851ebdc",
   "metadata": {},
   "source": [
    "Interesting, there is a strong positive corelation between the number of votes and the box office revenue.\n",
    "Let's visualize this in a scatter plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=full_movie_data_preprocessed, x='averageRating', y='log_numVotes', hue='log_box_office_revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e8e0e0",
   "metadata": {},
   "source": [
    "Now let's see at the difference between low and high rated movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the movies by the median rating\n",
    "median_rating = full_movie_data_preprocessed['averageRating'].median()\n",
    "\n",
    "# Add a column to the DataFrame to indicate if the movie has a high rating\n",
    "full_movie_data_preprocessed['high_rating'] = full_movie_data_preprocessed['averageRating'] > median_rating\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "sns.histplot(data=full_movie_data_preprocessed, x=\"runtime\", bins=50, ax=axes[0], kde=True, label=\"High rating\", hue=\"high_rating\")\n",
    "axes[0].set_title(\"Runtime distribution for high and low rating movies\")\n",
    "axes[0].set_xlabel(\"Runtime (min)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogram for the box office results\n",
    "sns.histplot(data=full_movie_data_preprocessed, x=\"box_office_revenue\", bins=50, ax=axes[1], kde=True, log_scale=True, label=\"High rating\", hue=\"high_rating\")\n",
    "axes[1].set_title(\"Box office revenue distribution for high and low rating movies\")\n",
    "axes[1].set_xlabel(\"Box office revenue (dollars, log scale)\")\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "# Histogram for the release date\n",
    "sns.histplot(data=full_movie_data_preprocessed, x=\"movie_release_date\", bins=50, ax=axes[2], kde=True, label=\"High rating\", hue=\"high_rating\")\n",
    "axes[2].set_title(\"Release date distribution for high and low rating movies\")\n",
    "axes[2].set_xlabel(\"Release date\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the movies by the median rating\n",
    "median_rating = full_movie_data_preprocessed['averageRating'].median()\n",
    "\n",
    "# Add a column to the DataFrame to indicate if the movie has a high rating\n",
    "full_movie_data_preprocessed['high_rating'] = full_movie_data_preprocessed['averageRating'] > median_rating\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "sns.histplot(data=full_movie_data_preprocessed, x=\"runtime\", bins=50, ax=axes[0], kde=True, label=\"High rating\", hue=\"high_rating\")\n",
    "axes[0].set_title(\"Runtime distribution for high and low rating movies\")\n",
    "axes[0].set_xlabel(\"Runtime (min)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogram for the box office results\n",
    "sns.histplot(data=full_movie_data_preprocessed, x=\"box_office_revenue\", bins=50, ax=axes[1], kde=True, log_scale=True, label=\"High rating\", hue=\"high_rating\")\n",
    "axes[1].set_title(\"Box office revenue distribution for high and low rating movies\")\n",
    "axes[1].set_xlabel(\"Box office revenue (dollars, log scale)\")\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "# Histogram for the release date\n",
    "sns.histplot(data=full_movie_data_preprocessed, x=\"movie_release_date\", bins=50, ax=axes[2], kde=True, label=\"High rating\", hue=\"high_rating\")\n",
    "axes[2].set_title(\"Release date distribution for high and low rating movies\")\n",
    "axes[2].set_xlabel(\"Release date\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785b295",
   "metadata": {},
   "source": [
    "We can observe a slight difference in the runtime distribution between high and low rated films.\n",
    "\n",
    "Now let's look at the number of votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Histogram for the number of votes\n",
    "sns.histplot(data=full_movie_data_preprocessed, x=\"numVotes\", bins=50, kde=True, log_scale=True, ax=ax, label=\"High rating\", hue=\"high_rating\")\n",
    "\n",
    "ax.set_title(\"Number of votes distribution for high and low rating movies\")\n",
    "ax.set_xlabel('Number of votes (log scale)')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column \n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "cutoff = 20 \n",
    "\n",
    "# Flatten the columns containing the lists of languages\n",
    "movie_languages_flat = movie_data_completed['languages'].apply(eval).explode()\n",
    "values = movie_languages_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "\n",
    "# Keep only the languages that are in the top cutoff\n",
    "movie_languages_flat = movie_languages_flat[movie_languages_flat.isin(values.index)]\n",
    "\n",
    "# Merge the languages with the high rating column\n",
    "movie_languages_flat = pd.merge(movie_languages_flat, full_movie_data_preprocessed['high_rating'], left_index=True, right_index=True)\n",
    "\n",
    "# Barplot for the languages distribution\n",
    "sns.countplot(data=movie_languages_flat, y=\"languages\", hue=\"high_rating\", ax=axes[0])\n",
    "axes[0].set_title(f\"{cutoff} most common languages\")\n",
    "axes[0].set_xlabel(\"Count\")\n",
    "axes[0].set_ylabel(\"Language\")\n",
    "\n",
    "# Flatten the columns containing the lists of countries\n",
    "movie_countries_flat = movie_data_completed['countries'].apply(eval).explode()\n",
    "values = movie_countries_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "\n",
    "# Keep only the countries that are in the top cutoff\n",
    "movie_countries_flat = movie_countries_flat[movie_countries_flat.isin(values.index)]\n",
    "\n",
    "# Merge the countries with the high rating column\n",
    "movie_countries_flat = pd.merge(movie_countries_flat, full_movie_data_preprocessed['high_rating'], left_index=True, right_index=True)\n",
    "\n",
    "# Barplot for the countries distribution\n",
    "sns.countplot(data=movie_countries_flat, y=\"countries\", hue=\"high_rating\", ax=axes[1])\n",
    "axes[1].set_title(f\"{cutoff} most common countries\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Country\")\n",
    "\n",
    "# Flatten the columns containing the lists of genres\n",
    "movie_genres_flat = movie_data_completed['genres'].apply(eval).explode()\n",
    "values = movie_genres_flat.value_counts()\n",
    "values = values[:genres_cutoff]\n",
    "\n",
    "# Keep only the genres that are in the top cutoff\n",
    "movie_genres_flat = movie_genres_flat[movie_genres_flat.isin(values.index)]\n",
    "\n",
    "# Merge the genres with the high rating column\n",
    "movie_genres_flat = pd.merge(movie_genres_flat, full_movie_data_preprocessed['high_rating'], left_index=True, right_index=True)\n",
    "\n",
    "# Countplot for the languages distribution\n",
    "sns.countplot(data=movie_genres_flat, y=\"genres\", hue=\"high_rating\", ax=axes[2])\n",
    "axes[2].set_title(f\"{genres_cutoff} most common genres\")\n",
    "axes[2].set_xlabel(\"Count\")\n",
    "axes[2].set_ylabel(\"Genre\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d6423",
   "metadata": {},
   "source": [
    "Now let's have a look at the difference in lead actors' attributes between high and low rating movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(full_movie_data_preprocessed, lead_actors_data_on_subset_movie, left_on='freebase_movie_id', right_on='freebase_movie_id')\n",
    "\n",
    "merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf0f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the height of actors\n",
    "sns.histplot(data=merged, x=\"actor_height\", bins=25, ax=axes[0], kde=False, hue='high_rating')\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "\n",
    "# Histogram for the actors' age at release\n",
    "sns.histplot(data=merged, x=\"actor_age_at_release\", bins=25, ax=axes[1], kde=True, hue='high_rating')\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "axes[1].legend(title=\"High rating\")\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=merged, x=\"actor_dob\", bins=25, ax=axes[2], kde='high_rating', hue='high_rating')\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e01ac",
   "metadata": {},
   "source": [
    "Not much of a difference here, let's look at the categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11288003",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Countplot for the gender distribution\n",
    "sns.countplot(data=merged, x=\"actor_gender\", ax=axes[0], stat='proportion', hue='high_rating')\n",
    "axes[0].set_title(\"Actor gender distribution\")\n",
    "axes[0].set_xlabel(\"Gender\")\n",
    "axes[0].set_ylabel(\"Proportion\")\n",
    "axes[0].legend(title='High rating')\n",
    "\n",
    "\n",
    "\n",
    "movie_countries_flat = movie_data_completed['countries'].apply(eval).explode()\n",
    "values = movie_countries_flat.value_counts()\n",
    "values = values[:cutoff]\n",
    "\n",
    "# Keep only the countries that are in the top cutoff\n",
    "movie_countries_flat = movie_countries_flat[movie_countries_flat.isin(values.index)]\n",
    "\n",
    "# Merge the countries with the high rating column\n",
    "movie_countries_flat = pd.merge(movie_countries_flat, full_movie_data_preprocessed['high_rating'], left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ethnicity_cutoff = 30\n",
    "ethnicity = merged[\"actor_ethnicity_label\"].copy()\n",
    "values = ethnicity.value_counts()\n",
    "values = values[:ethnicity_cutoff]\n",
    "\n",
    "ethnicity = ethnicity[ethnicity.isin(values.index)]\n",
    "ethnicity = pd.merge(ethnicity, merged[\"high_rating\"], left_index=True, right_index=True)\n",
    "\n",
    "sns.countplot(data=ethnicity, y=\"actor_ethnicity_label\", hue='high_rating', ax=axes[1]) \n",
    "axes[1].set_title(f\"{ethnicity_cutoff} most common ethnicity label\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Ethnicity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
