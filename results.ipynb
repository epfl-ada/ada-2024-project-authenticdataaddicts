{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddaee4c",
   "metadata": {},
   "source": [
    "# CMU Movie data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5340b",
   "metadata": {},
   "source": [
    "## Initial data inspection\n",
    "We will first try to provide a first generic inspection of the CMU movie dataset we decided to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b837b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from src.utils.data_utils import *\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f50aa3",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "The dataset is divided in 3 parts, the characters, the movies and the plots of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data, movie_data, plot_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd05ad",
   "metadata": {},
   "source": [
    "### Characters dataset\n",
    "Let's first have a look to the character dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b789d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {character_data.shape[0]} characters with {character_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72305a3",
   "metadata": {},
   "source": [
    "We can note that the actor ethnicity need to be transform to readable value (for now, it looks to be freebase id)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4b58d",
   "metadata": {},
   "source": [
    "Let's now see if we have a lot of missing data. We will also check that we don't have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec456244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the characters dataset for each features:\")\n",
    "print(character_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec919b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {character_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471ea5a",
   "metadata": {},
   "source": [
    "We see that we miss a lot of character names/ids, actor heights, actor ethnicity and actor age at release."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4be89",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "Let's now have a look to the movies dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af339272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {movie_data.shape[0]} movies with {movie_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcaf5d",
   "metadata": {},
   "source": [
    "We can note that the languages, countries and genres need to be preprocessed (for now dictionnary with id->readablename).\n",
    "We can also imagine to add a column movie_release_year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a5ea",
   "metadata": {},
   "source": [
    "Let's now see if we have a lot of missing data. We will also verify that we dont' have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82985100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the movies dataset for each features:\")\n",
    "print(movie_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465283a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {movie_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71496d7e",
   "metadata": {},
   "source": [
    "Ouch! We only have box office revenue for 10% of our movies, that's not good news since it's a key feature in our research problematic, we will need to fix this. Apart from this, we can also note that we are missing 25% of the runtime information. We could try to improve this. This also applies to the movie release data. For the languages, countries and genres, we note that they are dictionaries meaning that we first need to preprocess them a bit (for example transforming them to a list) to then be able to see the percentage of missing data. We will do it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the readable values for 'languages', 'countries', and 'genres' columns. Also clean the language column.\n",
    "\n",
    "movie_data['languages'] = movie_data['languages'].apply(lambda x: extract_values(x, clean_func=clean_language))\n",
    "movie_data['countries'] = movie_data['countries'].apply(lambda x: extract_values(x)) \n",
    "movie_data['genres'] = movie_data['genres'].apply(lambda x: extract_values(x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f611732",
   "metadata": {},
   "source": [
    "We can now have a look to the missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of None (NaN) values for each column\n",
    "none_languages = movie_data['languages'].isna().mean()\n",
    "none_countries = movie_data['countries'].isna().mean()\n",
    "none_genres = movie_data['genres'].isna().mean()\n",
    "\n",
    "# Print the counts of None (NaN) values\n",
    "print(f\"Percentage of None values in 'languages': {none_languages:.2%}\")\n",
    "print(f\"Percentage of None values in 'countries': {none_countries:.2%}\")\n",
    "print(f\"Percentage of None values in 'genres': {none_genres:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6999f",
   "metadata": {},
   "source": [
    "This looks ok overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ee937",
   "metadata": {},
   "source": [
    "### Plot summary dataset\n",
    "Let's now have a look to the plot summaries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {plot_data.shape[0]} plot summaries with {plot_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f05e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec2b3e",
   "metadata": {},
   "source": [
    "Let's see if we have some rows that are invalid (no summary or wikipedia id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead77807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pourcentage of null rows in the plot summaries dataset:\")\n",
    "print(plot_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353cf7c",
   "metadata": {},
   "source": [
    "Good new, we have nothing missing here :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5a1f3",
   "metadata": {},
   "source": [
    "## Data completion + first preprocessing\n",
    "Before going deeper to the analysis, we want to already fix some problems we pointed out.\n",
    "\n",
    "Movies:\n",
    "- A lot of box office revenus missing\n",
    "- We can also imagine to add a column movie_release_year.\n",
    "\n",
    "Characters:\n",
    "- We see that we miss a lot of character names/ids, actor heights, actor ethnicity and actor age at release.\n",
    "- We first note that we need to preprocess the actor ethnicity that look to be a freebase id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db19e1f",
   "metadata": {},
   "source": [
    "### Movies problems\n",
    "\n",
    "Let's first to get more data on box office results to decrease the number of missing data we have for now. To do this, we will merge the current dataset with differents other datasets that contain box office results (and also runtime since we have 25% of missing). Let's first add the Wikidata dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from wikidata\n",
    "with open('data/wikidata.json', 'r') as f:\n",
    "    wikidata_json = json.load(f)\n",
    "wikidata = pd.DataFrame(wikidata_json)\n",
    "\n",
    "# We rename some columns for merging after\n",
    "wikidata['box_office_revenue'] = pd.to_numeric(wikidata['box_office'], errors='coerce') \n",
    "wikidata['movie_name'] = wikidata['title'].astype(str)\n",
    "wikidata.drop(columns=['box_office', 'title'], inplace=True)\n",
    "\n",
    "wikidata.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd1e62",
   "metadata": {},
   "source": [
    "Amazing, we have the freebase id and the box office, we just now need to merge them with the current dataframe.\n",
    "We will first merge on the freebase ID and then on the movie title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_wikidata_merged, before_missing, after_missing = merge_for_completion(movie_data, wikidata, \"freebase_movie_id\", \"freebase_id\", \"box_office_revenue\", merge_strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on freebase ID) with wikidata: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on freebase ID) with wikidata: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05483e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_wikidata_merged, before_missing, after_missing = merge_for_completion(movies_wikidata_merged, wikidata, \"movie_name\", \"movie_name\", \"box_office_revenue\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac46c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on title) with wikidata: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on title) with wikidata: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526706b",
   "metadata": {},
   "source": [
    "It's not a big improvement but it's a good start. Let's now do the same with another dataset named 'The Movies Dataset' from https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?resource=download. Since we don't have the freebase ID, we will directly merge on the movie title. Note that we will also try to complete the missing data on runtime since this dataset has it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset (and rename some columns)\n",
    "movies_dataset = pd.read_csv('data/movies_metadata.csv')\n",
    "movies_dataset['box_office_revenue'] = pd.to_numeric(movies_dataset['revenue'], errors='coerce') \n",
    "movies_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_wikidata_merged, before_missing, after_missing = merge_for_completion(movies_wikidata_merged, movies_dataset, \"movie_name\", \"original_title\", \"box_office_revenue\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1919dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on title) with The Movies Dataset: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on title) with The Movies Dataset: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7011b5",
   "metadata": {},
   "source": [
    "Good improvement! Let's do the same for the runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f19049",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_wikidata_merged, before_missing, after_missing = merge_for_completion(movies_wikidata_merged, movies_dataset, \"movie_name\", \"original_title\", \"runtime\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Runtime results missing percentage before merge (on title) with The Movies Dataset: {before_missing:.2%}\")\n",
    "print(f\"Runtime results missing percentage after merge (on title) with The Movies Dataset: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65eaf2",
   "metadata": {},
   "source": [
    "Small improvement but we take it. Let's try to use another dataset to complete..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66574c84",
   "metadata": {},
   "source": [
    "Lets try a new dataset that contains more revenue data. This data set contains information about 10,000 movies collected from The Movie Database (TMDb), including user imdb_ratings and revenue. https://d17h27t6h515a5.cloudfront.net/topher/2017/October/59dd1c4c_tmdb-movies/tmdb-movies.csv. As above we rename the revenue column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset (and rename some columns)\n",
    "tmdb_movies_dataset = pd.read_csv('data/tmdb_movies.csv')\n",
    "tmdb_movies_dataset['box_office_revenue'] = pd.to_numeric(tmdb_movies_dataset['revenue'], errors='coerce') \n",
    "tmdb_movies_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_wikidata_merged, before_missing, after_missing = merge_for_completion(movies_wikidata_merged, tmdb_movies_dataset, \"movie_name\", \"original_title\", \"box_office_revenue\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on title) with The Movies Dataset: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on title) with The Movies Dataset: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfd011",
   "metadata": {},
   "source": [
    "Now we want to merge with the IMDb datasets (https://developer.imdb.com/non-commercial-datasets/) in order to obtain ratings and lead actors. We set consider an actor a lead actor if their ordering is 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_merge = wikidata[['freebase_id', 'IMDb_ID']]\n",
    "wikidata_merge = wikidata_merge.rename(columns={'freebase_id': 'freebase_movie_id'})\n",
    "\n",
    "movies_wikidata_merged_imdbid = pd.merge(wikidata_merge, movies_wikidata_merged, on='freebase_movie_id', how='inner')\n",
    "movies_wikidata_merged_imdbid.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c549c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "imdb_principals = pd.read_csv('data/title.principals.tsv', sep='\\t')\n",
    "imdb_names = pd.read_csv('data/name.basics.tsv', sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ratings = imdb_ratings.rename(columns={'tconst': 'IMDb_ID'})\n",
    "imdb_ratings = imdb_ratings[['IMDb_ID', 'averageRating', 'numVotes']]  \n",
    "\n",
    "lead_actors = imdb_principals[(imdb_principals['category'].isin(['actor', 'actress'])) & (imdb_principals['ordering'].isin([1, 2]))]\n",
    "lead_actors = lead_actors.rename(columns={'tconst': 'IMDb_ID'})\n",
    "lead_actors = lead_actors[['IMDb_ID', 'nconst', 'ordering']]\n",
    "\n",
    "lead_actors = lead_actors.merge(imdb_names[['nconst', 'primaryName']], on='nconst', how='left')\n",
    "lead_actors = lead_actors.pivot(index='IMDb_ID', columns='ordering', values='primaryName').reset_index()\n",
    "lead_actors.columns = ['IMDb_ID', 'lead_actor_1', 'lead_actor_2']\n",
    "\n",
    "imdb_merged_movie_data = pd.merge(movies_wikidata_merged_imdbid, imdb_ratings, on='IMDb_ID', how='left')\n",
    "imdb_merged_movie_data.head(2)\n",
    "\n",
    "merged_movie_data = imdb_merged_movie_data.merge(lead_actors, left_on='IMDb_ID', right_on='IMDb_ID', how='left')\n",
    "merged_movie_data.head(2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db28a2",
   "metadata": {},
   "source": [
    "## Cleaning and removing outliers\n",
    "\n",
    "Before analyzing the data any further, let's remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9903b82",
   "metadata": {},
   "source": [
    "### Character dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only non NaN values\n",
    "not_na_height = character_data[\"actor_height\"].notna()\n",
    "not_na_age_at_release = character_data[\"actor_age_at_release\"].notna()\n",
    "not_na_gender = character_data[\"actor_gender\"].notna()\n",
    "not_na_ethnicity = character_data[\"actor_ethnicity\"].notna()\n",
    "\n",
    "not_na_mask = not_na_height & not_na_age_at_release & not_na_gender & not_na_ethnicity\n",
    "character_data_cleaned = character_data[not_na_mask]\n",
    "\n",
    "reduction = 1 - character_data_cleaned.shape[0] / character_data.shape[0]\n",
    "print(f\"Removing NaN reduced the dataset by: {reduction:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fceddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid heights (between 1.5 and 2.8 meters)\n",
    "character_data_valid_heights = character_data_cleaned.query(\"actor_height > 1.5 and actor_height < 2.8\")\n",
    "reduction = (len(character_data_cleaned) - len(character_data_valid_heights)) / len(character_data_cleaned)\n",
    "\n",
    "print(f\"Removing invalid actor heights reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2568b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid ages (between 0 and 100 years)\n",
    "character_data_valid_ages = character_data_valid_heights.query(\"actor_age_at_release > 0 and actor_age_at_release < 100\")\n",
    "reduction = (len(character_data_valid_heights) - len(character_data_valid_ages)) / len(character_data_valid_heights)\n",
    "\n",
    "print(f\"Removing invalid actor ages reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only ethnicity labels that are common\n",
    "min_occurrence = 10\n",
    "ethnicity_label_counts = character_data_valid_ages['actor_ethnicity_label'].value_counts()\n",
    "ethnicity_labels = ethnicity_label_counts[ethnicity_label_counts > min_occurrence]\n",
    "\n",
    "mask = character_data_valid_ages['actor_ethnicity_label'].isin(ethnicity_labels.index)\n",
    "character_data_valid_ethnicity = character_data_valid_ages[mask]\n",
    "\n",
    "reduction = 1 - len(character_data_valid_ethnicity) / len(character_data_valid_ages)\n",
    "\n",
    "print(f\"Removing ethnicity labels which are uncommon reduced that dataset by {reduction:.2%}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data_valid = character_data_valid_ethnicity\n",
    "\n",
    "# Convert the date of birth to datetime\n",
    "character_data_valid[\"actor_dob\"] = pd.to_datetime(character_data_valid[\"actor_dob\"], errors='coerce')\n",
    "\n",
    "print(f\"Final character dataset size: {len(character_data_valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab0a23",
   "metadata": {},
   "source": [
    "## Deeper analysis\n",
    "Now that our data is more complete, we can do a more in deep analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951bc2b",
   "metadata": {},
   "source": [
    "### Character dataset \n",
    "\n",
    "Let's first analyse our character dataset. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data_valid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74caf699",
   "metadata": {},
   "source": [
    "Let's print their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "sns.histplot(data=character_data_valid, x=\"actor_height\", bins=50, ax=axes[0], kde=False)\n",
    "axes[0].set_title(\"Height of the actor\")\n",
    "axes[0].set_xlabel(\"Height (m)\")\n",
    "\n",
    "# Histogram for the box office results\n",
    "sns.histplot(data=character_data_valid, x=\"actor_age_at_release\", bins=50, ax=axes[1], kde=True)\n",
    "axes[1].set_title(\"Age of the actor at the release of the movie\")\n",
    "axes[1].set_xlabel(\"Age (years)\")\n",
    "\n",
    "# Histogram for the character date of birth\n",
    "sns.histplot(data=character_data_valid, x=\"actor_dob\", bins=50, ax=axes[2], kde=True)\n",
    "axes[2].set_title(\"Date of birth of the actor\")\n",
    "axes[2].set_xlabel(\"Date of birth\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5558c",
   "metadata": {},
   "source": [
    "Let's now lets explore the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeaf59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Countplot for the gender distribution\n",
    "sns.countplot(data=character_data_valid, x=\"actor_gender\", ax=axes[0], stat='proportion')\n",
    "axes[0].set_title(\"Actor gender distribution\")\n",
    "axes[0].set_xlabel(\"Gender\")\n",
    "axes[0].set_ylabel(\"Proportion\")\n",
    "\n",
    "ethnicity_cutoff = 30\n",
    "values = character_data_valid[\"actor_ethnicity_label\"].value_counts()\n",
    "values = values[:ethnicity_cutoff]\n",
    "sns.barplot(x=values, y=values.index, ax=axes[1])\n",
    "axes[1].set_title(f\"{ethnicity_cutoff} most common ethnicity label\")\n",
    "axes[1].set_xlabel(\"Count\")\n",
    "axes[1].set_ylabel(\"Ethnicity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7792b",
   "metadata": {},
   "source": [
    "### Movies dataset \n",
    "\n",
    "Let's now analyse our movies dataset. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_completed = merged_movie_data.copy()\n",
    "movie_data_completed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041fe56",
   "metadata": {},
   "source": [
    "TODO: Comment this, also note the max of runtime very big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9a852",
   "metadata": {},
   "source": [
    "Let's print their distributions (except for the wikipedia id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "movie_data_completed[\"runtime\"].hist(bins=100, ax=axes[0])\n",
    "axes[0].set_title(\"Histogram for runtime\")\n",
    "axes[0].set_xlabel(\"Runtime (min)\")\n",
    "\n",
    "# Histogram for the box office results\n",
    "movie_data_completed[\"box_office_revenue\"].hist(bins=100, ax=axes[1])\n",
    "axes[1].set_title(\"Histogram for box_office_revenue\")\n",
    "axes[1].set_xlabel(\"Box office revenue (dollars)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061978c7",
   "metadata": {},
   "source": [
    "Not really ideal because of the outliers and the spread of the data, let's use a log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram for the runtime\n",
    "np.log1p(movie_data_completed[\"runtime\"]).hist(bins=30, ax=axes[0])\n",
    "axes[0].set_title(\"Log-Transformed Histogram for Runtime\")\n",
    "\n",
    "# Histogram for the box office results (log-transformed)\n",
    "np.log1p(movie_data_completed[\"box_office_revenue\"]).hist(bins=30, ax=axes[1])\n",
    "axes[1].set_title(\"Log-Transformed Histogram for Box Office Revenue\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2f59c",
   "metadata": {},
   "source": [
    "Let's now print some box plots (also with log transformation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Boxplot for the log-transformed box_office_revenue\n",
    "sns.boxplot(data=np.log1p(movie_data_completed[\"box_office_revenue\"]), ax=axes[0])\n",
    "axes[0].set_title(\"Log-Transformed Boxplot for box_office_revenue\")\n",
    "\n",
    "# Boxplot for the log-transformed runtime\n",
    "sns.boxplot(data=np.log1p(movie_data_completed[\"runtime\"]), ax=axes[1])\n",
    "axes[1].set_title(\"Log-Transformed Boxplot for runtime\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b2558",
   "metadata": {},
   "source": [
    "TODO: MAYBE TRY TO DO A BETTER plot for box office"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c2eb7",
   "metadata": {},
   "source": [
    "We can now have a look to the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: SOME COUNT PLOTS FOR CATEGORICAL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
