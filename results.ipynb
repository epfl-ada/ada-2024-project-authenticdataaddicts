{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddaee4c",
   "metadata": {},
   "source": [
    "# CMU Movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b837b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "from src.data_completion import *\n",
    "from src.data_preprocessing import *\n",
    "from src.data_loading import *\n",
    "from src.data_fetching import *\n",
    "from src.data_visualization import *\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8ac0f",
   "metadata": {},
   "source": [
    "## Download datasets\n",
    "The following code dowloads the datasets that were too heavy to be included, and places them directly in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d88e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download TMDb Dataset\n",
    "download_tmdb()\n",
    "\n",
    "# Download IMDb Dataset\n",
    "download_imdb(\"name.basics.tsv\")\n",
    "download_imdb(\"title.ratings.tsv\")\n",
    "download_imdb(\"title.principals.tsv\")\n",
    "\n",
    "# Download CMU dataset\n",
    "download_cmu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5340b",
   "metadata": {},
   "source": [
    "## Initial data inspection\n",
    "We will first try to provide a first generic inspection of the CMU movie dataset we decided to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f50aa3",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "The dataset is divided in 3 parts, the characters, the movies and the plots of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data, movie_data, plot_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd05ad",
   "metadata": {},
   "source": [
    "### Characters dataset\n",
    "Let's first have a look to the character dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b789d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {character_data.shape[0]} characters with {character_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72305a3",
   "metadata": {},
   "source": [
    "We directly note that the actor ethnicities are not human readable, they look to be freebase ids. It's something we will need to fix during preprocessing.\n",
    "Let's now see how much missing data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec456244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the characters dataset for each features:\")\n",
    "print(character_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2afd6",
   "metadata": {},
   "source": [
    "We see that we miss a lot of character names/ids, actor heights, ethnicity and age at release. We can also check for duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec919b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {character_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4be89",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "Let's now have a look at the movies dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af339272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {movie_data.shape[0]} movies with {movie_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a5ea",
   "metadata": {},
   "source": [
    "Let's now see if we have a lot of missing data. We will also verify that we don't have duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82985100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of null rows in the movies dataset for each features:\")\n",
    "print(movie_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465283a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicated rows: {movie_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71496d7e",
   "metadata": {},
   "source": [
    "Ouch! We only have box office revenue for 10% of our movies, that's not good news since it's a key feature in our research problematic, we will need to fix this. Apart from this, we can also note that we are missing 25% of the runtime information. We could try to improve this. This also applies to the movie release data. For the languages, countries and genres, we note that they are dictionaries meaning that we first need to preprocess them a bit (for example transforming them to a list) to then be able to see the percentage of missing data. We will do it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the readable values for 'languages', 'countries', and 'genres' columns. Also clean the language column.\n",
    "\n",
    "movie_data['languages'] = movie_data['languages'].apply(lambda x: extract_values(x, clean_func=clean_language))\n",
    "movie_data['countries'] = movie_data['countries'].apply(lambda x: extract_values(x)) \n",
    "movie_data['genres'] = movie_data['genres'].apply(lambda x: extract_values(x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f611732",
   "metadata": {},
   "source": [
    "We can now have a look to the missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of None (NaN) values for each column\n",
    "none_languages = movie_data['languages'].isna().mean()\n",
    "none_countries = movie_data['countries'].isna().mean()\n",
    "none_genres = movie_data['genres'].isna().mean()\n",
    "\n",
    "# Print the counts of None (NaN) values\n",
    "print(f\"Percentage of None values in 'languages': {none_languages:.2%}\")\n",
    "print(f\"Percentage of None values in 'countries': {none_countries:.2%}\")\n",
    "print(f\"Percentage of None values in 'genres': {none_genres:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6999f",
   "metadata": {},
   "source": [
    "We miss some data but nothing too huge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ee937",
   "metadata": {},
   "source": [
    "### Plot summary dataset\n",
    "Let's now have a look at the plot summaries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {plot_data.shape[0]} plot summaries with {plot_data.shape[1]} features for each.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f05e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec2b3e",
   "metadata": {},
   "source": [
    "Let's see if we have some rows that are invalid (no summary or wikipedia id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead77807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pourcentage of null rows in the plot summaries dataset:\")\n",
    "print(plot_data.isnull().mean().round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353cf7c",
   "metadata": {},
   "source": [
    "Good new, we have nothing missing here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5a1f3",
   "metadata": {},
   "source": [
    "## Data completion\n",
    "\n",
    "### Missing data\n",
    "Before going deeper to the analysis, we want to already fix the fact that we are missing data for most of the box office results and some runtime values.\n",
    "\n",
    "Let's then first to get more data on box office results to decrease the number of missing data we have for now. To do this, we will merge the current dataset with a dataset that contains information about 1,000,000 movies collected from The Movie Database (TMDb), including revenue and runtime (https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset (and rename some columns)\n",
    "movies_dataset = pd.read_csv('data/tmbd_movies.csv')\n",
    "movies_dataset['box_office_revenue'] = pd.to_numeric(movies_dataset['revenue'], errors='coerce') \n",
    "movies_dataset['release_date'] = pd.to_datetime(movies_dataset['release_date'], errors='coerce')\n",
    "\n",
    "# We remove the nan of movie release date since we merge on it\n",
    "movie_data['movie_release_date'] = pd.to_datetime(movie_data['movie_release_date'], errors='coerce')\n",
    "movie_data = movie_data.dropna(subset=['movie_release_date'])\n",
    "\n",
    "movies_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"box_office_revenue\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac46c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Box office results missing percentage before merge (on title) with wikidata: {before_missing:.2%}\")\n",
    "print(f\"Box office results missing percentage after merge (on title) with wikidata: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7011b5",
   "metadata": {},
   "source": [
    "Big improvement, that's good. Let's try to improve the runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f19049",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, before_missing, after_missing = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"runtime\", merge_strategy='prioritize_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the before and after missing percentages\n",
    "print(f\"Runtime results missing percentage before merge (on title) with The Movies Dataset: {before_missing:.2%}\")\n",
    "print(f\"Runtime results missing percentage after merge (on title) with The Movies Dataset: {after_missing:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc622e09",
   "metadata": {},
   "source": [
    "That's pretty cool too, we also want to merge the IMBD ID column because we need it afterwards (and we don't have it with the CMU dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_merged, _, _ = merge_for_completion(movie_data_merged, movies_dataset, [\"movie_name\", \"movie_release_date\"], [\"title\", \"release_date\"], \"imdb_id\", merge_strategy='add_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfd011",
   "metadata": {},
   "source": [
    "### Adding the rating and lead actors of movies\n",
    "\n",
    "Now we want to merge with the IMDb datasets (https://developer.imdb.com/non-commercial-datasets/) in order to obtain ratings and lead actors. We consider an actor to be a lead actor if their ordering is 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb ratings and select relevant columns\n",
    "imdb_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "imdb_ratings = imdb_ratings.rename(columns={'tconst': 'imdb_id'})\n",
    "imdb_ratings = imdb_ratings[['imdb_id', 'averageRating', 'numVotes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb names data for actors\n",
    "imdb_names = pd.read_csv('data/name.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c549c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract lead actors (representing the first and second roles)\n",
    "filtered_lead_actors = extract_lead_actors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the lead actors into movie data\n",
    "movie_data_merged = merge_lead_actors_and_ratings(movie_data_merged, imdb_names, imdb_ratings, filtered_lead_actors)\n",
    "movie_data_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d15017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {movie_data_merged.shape[0]} rows in our merged movies dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db28a2",
   "metadata": {},
   "source": [
    "## Cleaning and removing outliers\n",
    "\n",
    "Before analyzing the data any further, let's clean our data and remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9903b82",
   "metadata": {},
   "source": [
    "### Character dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8438f2",
   "metadata": {},
   "source": [
    "First thing we want to do is to make our ethnicites human readable. To do it we used the wikidata API to map the IDs. We created a CSV file to avoid making multiple request each time we run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_character_data = map_ethnicities(character_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9ceea",
   "metadata": {},
   "source": [
    "We can now do more basic preprocessing. For more details, please have a look to our function in src/data_preprocessing.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data_valid = preprocess_characters(merged_character_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final dataset size\n",
    "print(f\"Number of characters after preprocessing: {character_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "character_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae88aa",
   "metadata": {},
   "source": [
    "This is good. We don't care about the movie_release_date here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e02989",
   "metadata": {},
   "source": [
    "### Movies dataset\n",
    "\n",
    "We will also remove the outliers and preprocess the movie dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_valid = preprocess_movies(movie_data_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0252f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of movies after preprocessing: {movie_data_valid.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no nan values still there\n",
    "movie_data_valid.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33d6f9",
   "metadata": {},
   "source": [
    "That looks perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893cdd2",
   "metadata": {},
   "source": [
    "## Movies subset creation with complete lead actors data \n",
    "\n",
    "Now that we have the two main actors of each movie, let's see if we have corresponding characteristics in the preprocessed character dataset. First we will extract the characters data of all our lead actors in all our films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_actor_data = extract_movies_with_lead_actors_data(movie_data_valid, character_data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653bfc3",
   "metadata": {},
   "source": [
    "No missing value makes sense since we preprocessed our character data. Let's try now to see how much data we have on our lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have data for {lead_actor_data.shape[0]/(movie_data_valid[\"lead_actor_1\"].notna().sum() + movie_data_valid[\"lead_actor_2\"].notna().sum())*100}% ({lead_actor_data.shape[0]} actors) of our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be30b0",
   "metadata": {},
   "source": [
    "Ok good, let's now create a subset dataframe that will contains only the movies for which we have complete data on the lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd31290",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_movies_with_lead_actors_data = movie_data_valid[movie_data_valid['freebase_movie_id'].isin(lead_actor_data['freebase_movie_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_movies_with_lead_actors_data.shape[0]} movies for which we have full data on our lead actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34957642",
   "metadata": {},
   "source": [
    "Now that we have this movies subset, we can extract the corresponding lead actors and characters subsets for these movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the character_data_valid dataset to keep only rows with freebase_movie_id present in movie_data_extracted\n",
    "subset_characters_with_lead_actor_data = character_data_valid[character_data_valid['freebase_movie_id'].isin(subset_movies_with_lead_actors_data['freebase_movie_id'])]\n",
    "\n",
    "# Extract the relevant columns for characters and associated movies\n",
    "subset_characters_with_lead_actor_data = subset_characters_with_lead_actor_data[['actor_name', 'actor_dob', 'actor_gender', 'actor_ethnicity_label', 'actor_height', 'actor_age_at_release', 'freebase_movie_id', 'character_name']]\n",
    "\n",
    "# Display the first few rows of the filtered and extracted data\n",
    "subset_characters_with_lead_actor_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_characters_with_lead_actor_data.shape[0]} characters for the movies subset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_lead_actors = extract_movies_with_lead_actors_data(subset_movies_with_lead_actors_data, character_data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77311f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {subset_lead_actors.shape[0]} lead actors for the movies subset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56351b7",
   "metadata": {},
   "source": [
    "## Saving our newly created dataframes\n",
    "\n",
    "We will save our five dataframes:\n",
    "\n",
    "- full_movie_data_preprocessed that contains all the movies preprocessed \n",
    "- full_characters_data_preprocessed that contains all the characters preprocessed\n",
    "- subset_movies_with_lead_actors_data that contains movies where we have data on all the lead actors\n",
    "- lead_actors_data_on_subset_movie that contains information on the lead actors of the previous subset\n",
    "- character_data_valid_filtered that contains information on all the characters of the previous subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_path = 'data/preprocessed'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(preprocessed_path, exist_ok=True)\n",
    "\n",
    "preprocessed_names = {\n",
    "    'full_movie_data_preprocessed.csv': movie_data_valid,\n",
    "    'full_characters_data_preprocessed.csv': character_data_valid,\n",
    "    'subset_movie_with_full_data_on_lead_actors.csv': subset_movies_with_lead_actors_data,\n",
    "    'lead_actors_data_on_subset_movie.csv': subset_lead_actors,\n",
    "    'characters_data_on_subset_movie.csv': subset_characters_with_lead_actor_data\n",
    "}\n",
    "\n",
    "for name, df in preprocessed_names.items():\n",
    "    df.to_csv(os.path.join(preprocessed_path, name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356afe5",
   "metadata": {},
   "source": [
    "## Loading our preprocessed dataframes\n",
    "\n",
    "We can skip all the preprocessing process and load our dataframes directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed datasets\n",
    "full_movie_data_preprocessed = pd.read_csv('data/preprocessed/full_movie_data_preprocessed.csv')\n",
    "full_characters_data_preprocessed = pd.read_csv('data/preprocessed/full_characters_data_preprocessed.csv')\n",
    "subset_movie_with_full_data_on_lead_actors = pd.read_csv('data/preprocessed/subset_movie_with_full_data_on_lead_actors.csv')\n",
    "lead_actors_data_on_subset_movie = pd.read_csv('data/preprocessed/lead_actors_data_on_subset_movie.csv')\n",
    "characters_data_on_subset_movie = pd.read_csv('data/preprocessed/characters_data_on_subset_movie.csv')\n",
    "\n",
    "# We must convert dates to datetime\n",
    "lead_actors_data_on_subset_movie['actor_dob'] = pd.to_datetime(lead_actors_data_on_subset_movie['actor_dob'])\n",
    "characters_data_on_subset_movie['actor_dob'] = pd.to_datetime(characters_data_on_subset_movie['actor_dob'])\n",
    "full_movie_data_preprocessed['movie_release_date'] = pd.to_datetime(full_movie_data_preprocessed['movie_release_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab0a23",
   "metadata": {},
   "source": [
    "## Deeper analysis\n",
    "Now that our data is more complete, we can do a more in deep analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951bc2b",
   "metadata": {},
   "source": [
    "### Lead actors dataset \n",
    "\n",
    "Let's first analyze our dataframe with the lead actors just created. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_actors_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74caf699",
   "metadata": {},
   "source": [
    "Let's print their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_actors(lead_actors_data_on_subset_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067ac33",
   "metadata": {},
   "source": [
    "Let's now explore the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_actors(lead_actors_data_on_subset_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d287f74",
   "metadata": {},
   "source": [
    "We can visualize here the correlation matrix between the numerical attributes of the actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d94a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "lead_actors_for_corr = lead_actors_data_on_subset_movie[['actor_height', 'actor_age_at_release', 'actor_dob']]\n",
    "# Convert gender to boolean by getting dummies\n",
    "lead_actors_gender_dummies = pd.get_dummies(lead_actors_for_corr['actor_gender'])\n",
    "lead_actors_for_corr.drop('actor_gender', axis=1, inplace=True)\n",
    "lead_actors_for_corr = lead_actors_for_corr.join(lead_actors_gender_dummies)\n",
    "# lead_actors_for_corr['F'] = lead_actors_gender_dummies['F']\n",
    "# lead_actors_for_corr['M'] = lead_actors_gender_dummies['M']\n",
    "corr_matrix = lead_actors_for_corr.corr()\n",
    "label_names = ['Height', 'Age at release']\n",
    "ax = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', xticklabels=label_names, yticklabels=label_names)\n",
    "ax.set_title('Heatmap of some actors attributes');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7792b",
   "metadata": {},
   "source": [
    "### Movies dataset \n",
    "\n",
    "Let's now analyse our movies dataset. We will start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_completed = full_movie_data_preprocessed.copy()\n",
    "movie_data_completed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9a852",
   "metadata": {},
   "source": [
    "Let's print their distributions (except for the wikipedia id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_movies(movie_data_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c2eb7",
   "metadata": {},
   "source": [
    "Let's now look at the ratings and number of votes per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_movie_ratings(movie_data_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfe28f",
   "metadata": {},
   "source": [
    "We can now have a look at the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_movies(movie_data_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95a393",
   "metadata": {},
   "source": [
    "As we can expect, the English language and United States of America clearly dominate the movie industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f48297",
   "metadata": {},
   "source": [
    "### Characters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceeae5f",
   "metadata": {},
   "source": [
    "We now analyze the dataframe with the characters (including non-lead actors). We again start with a summary of the statistics of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff57aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_data_on_subset_movie.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c2f07",
   "metadata": {},
   "source": [
    "Let's do some plots to visualize better. As it is very similar as the plots from the lead actors dataset, we will compare our plots with the ones from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "histogram_actors(characters_data_on_subset_movie, axes=axes)\n",
    "histogram_actors(lead_actors_data_on_subset_movie, axes=axes)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend([\"All actors\", \"Lead actors\"], loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2ecd5",
   "metadata": {},
   "source": [
    "Finally we compare the gender distribution between all actors and only lead actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556887b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 6))\n",
    "width = 0.4\n",
    "\n",
    "gender_dist_all = characters_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "gender_dist_lead = lead_actors_data_on_subset_movie['actor_gender'].value_counts(normalize=True) * 100\n",
    "labels = list(gender_dist_all.keys())\n",
    "\n",
    "bar_all = ax.bar(labels, gender_dist_all, -width, label=\"All actors\", align='edge')\n",
    "bar_lead = ax.bar(labels, gender_dist_lead, width, label=\"Lead actors\", align='edge')\n",
    "\n",
    "ax.set_title(\"Comparison of actors' gender distribution between lead roles and all roles\")\n",
    "ax.set_xlabel(\"Gender\")\n",
    "ax.set_ylabel(\"Percent\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d49597",
   "metadata": {},
   "source": [
    "### Low vs. high rating/revenue analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e8e0e0",
   "metadata": {},
   "source": [
    "Now let's see at the difference between low and high rated movies as well as between movies with low and high box office revenues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the movies by the median rating and median box office revenue\n",
    "median_rating = full_movie_data_preprocessed['averageRating'].median()\n",
    "median_box_office = full_movie_data_preprocessed['box_office_revenue'].median()\n",
    "\n",
    "# Add a column to the DataFrame to indicate if the movie has a high rating/box office revenue\n",
    "full_movie_data_preprocessed['high_rating'] = full_movie_data_preprocessed['averageRating'] > median_rating\n",
    "full_movie_data_preprocessed['high_box_office'] = full_movie_data_preprocessed['box_office_revenue'] > median_box_office\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "histogram_movies(full_movie_data_preprocessed, hue=\"high_rating\", axes=axes[0])\n",
    "histogram_movies(full_movie_data_preprocessed, hue=\"high_box_office\", axes=axes[1])\n",
    "\n",
    "fig.suptitle(\"Comparison of movies with high/low ratings (first row) and high/low box office revenue (second row)\", fontsize=16)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785b295",
   "metadata": {},
   "source": [
    "First, we see that the box office was correctly split by low/high revenue (see second plot of the second row).\n",
    "\n",
    "Futhermore, we can observe a slight difference in the runtime distribution between high and low rated/revenue movies.\n",
    "\n",
    "Now let's look at the average ratings and number of votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "histogram_movie_ratings(full_movie_data_preprocessed, hue=\"high_rating\", axes=axes[0])\n",
    "histogram_movie_ratings(full_movie_data_preprocessed, hue=\"high_box_office\", axes=axes[1])\n",
    "\n",
    "fig.suptitle(\"Comparison of movies with high/low ratings (first row) and high/low box office revenue (second row)\", fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e28ef8",
   "metadata": {},
   "source": [
    "Again, we see that the data was correctly split into low and high rating (see first plot of the first row).\n",
    "\n",
    "Further, we can observe that high rated/revenue movies have more votes.\n",
    "\n",
    "Now, let's look at the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "count_movies(full_movie_data_preprocessed, hue=\"high_rating\", axes=axes[0])\n",
    "count_movies(full_movie_data_preprocessed, hue=\"high_box_office\", axes=axes[1])\n",
    "\n",
    "fig.suptitle(\"Comparison of movies with high/low ratings (first row) and high/low box office revenue (second row)\", fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d6423",
   "metadata": {},
   "source": [
    "We can see that there are more higher rated dramas than lower rated one, but there are less high box office revenue dramas as high revenue one.\n",
    "\n",
    "Futhermore, we see there are more lower rated comedies but they usually have higher box office revenues.\n",
    "\n",
    "Now let's have a look at the difference in lead actors' attributes between high and low rating movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the movie data with the lead actors data\n",
    "merged = pd.merge(full_movie_data_preprocessed, lead_actors_data_on_subset_movie, left_on='freebase_movie_id', right_on='freebase_movie_id')\n",
    "\n",
    "# Split the movies by the median rating and median box office revenue\n",
    "median_rating = merged['averageRating'].median()\n",
    "median_box_office = merged['box_office_revenue'].median()\n",
    "\n",
    "# Add a column to the DataFrame to indicate if the movie has a high rating/box office revenue\n",
    "merged['high_rating'] = merged['averageRating'] > median_rating\n",
    "merged['high_box_office'] = merged['box_office_revenue'] > median_box_office\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "histogram_actors(merged, hue='high_rating', axes=axes[0])\n",
    "histogram_actors(merged, hue='high_box_office', axes=axes[1])\n",
    "\n",
    "fig.suptitle(\"Comparison of movies with high/low ratings (first row) and high/low box office revenue (second row)\", fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e01ac",
   "metadata": {},
   "source": [
    "Not much of a difference here, let's look at the categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11288003",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "count_actors(merged, \"high_rating\", axes[0])\n",
    "count_actors(merged, \"high_box_office\", axes[1])\n",
    "\n",
    "fig.suptitle(\"Comparison of movies with high/low ratings (first row) and high/low box office revenue (second row)\", fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17eeed",
   "metadata": {},
   "source": [
    "We can see that there are more men in higher rated/revenue movies as in lower rated/revenue movies.\n",
    "Whereas, it's the opposite for women.\n",
    "\n",
    "Futhermore, we can see that there are more African Americans in lower rated movies as in high rated movies.\n",
    "Whereas, it't the opposite for English People.\n",
    "\n",
    "Interestingly, we see that there are more Affrican Americans in movies with high revenue as in lower box office revenue movies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
